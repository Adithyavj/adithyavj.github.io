[ { "title": "Azure Functions", "url": "/posts/azure-functions/", "categories": "Blogging, Programming", "tags": "development programming cloud azure functions", "date": "2022-10-14 16:10:00 +0530", "snippet": "IntroductionAzure function is an easy way to build the applications you need using simple serverless functions that scale automatically based to meet demand. No need to worry about infrastructure or provisioning servers. Azure functions provides as many or as few compute resources as need to meet the applications demand. A function is invoked using a trigger. Triggers have associated data, which is often provided as the payload of the function.Some of the Azure Functions triggers are: Http Trigger Timer Trigger Queue Trigger Blob TriggerAzure Durable FunctionsDurable functions is an extension of Auzre Functions that lets us write stateful functions (long running) in a serverless environment. Durable functions help solve many of the problems due to the stateless nature of functions.Serverless: (Why durable functions?)It is an abstraction of servers. There are real servers behind the scene that are powering serverless.A developer using serverless function can just focus on their code - there are no distractions around server management, availability etc.Serverless is event driven. It is only spun up when an event triggers the functions, it does it’s job and then spin back down.With serverless, no infrastructure management, auto-scale based on workload, and no wasted resources.FaaS (Functions-as-a-Service) is at the center of serverless. Single responsibility Short lived (Functions don’t stick around when finished executing) Stateless (Functions don’t hold any state and don’t rely on the state of any other process) Event driven &amp;amp; scalable (Functions respond to predefined events)If the task the Azure function has to perform is not short lived, simple, and stateless, that is when we move to durable functions.Introducing Durable FunctionsDurable functions is a free open source framework for azure functions that allows us to: Write long-running orchestrations as a single function while maintaining state for all the calls that need to happen while still running in a serverless wasy. Simplify complex transactions and coordination (Manage End to End flow). We can easily call function from another functions, synchronously or asynchronously.Components Starter Functions (What Trigger’s off this long running process) eg:- Http trigger, Queue trigger etc A trigger which will start off the orchestrations Orchestrator Function (It is the heart of the durable function) Coordinates activities - We put the orchestration logic here. Activity Function Performs individual tasks/work. We can run these in parallel, sequentially etc. Example of an orchestrator function// calls functions in sequencepublic static async Task&amp;lt;object&amp;gt; Run(DurableOrchestrationContext ctx) // Orchestrator Function{ try { // passing data sequentially one after the other. var x = await ctx.CallFunctionAsync(&quot;F1&quot;); // Activity Function var y = await ctx.CallFunctionAsync(&quot;F2&quot;, x); // Activity Function return await ctx.CallFunctionAsync(&quot;F3&quot;, y); // Activity Function } catch (Exception) { // global error handling/compensation goes here. }}// A sample orchestrationvar outputs = new List&amp;lt;string&amp;gt;();outputs.Add(await context.CallActivityAsync)&amp;lt;string&amp;gt;(&quot;SayHello&quot;, &quot;.NET&quot;));return outputs;What happens behind the scenes: When somebody triggers the starter function, it calls the orchestrator function Will look in the Execution History whether the activity function was already called and if not will execute it. Orchestrator function completes and scales back to zero. Now Activity function wakes up and executes it’s job and lets Orchestrator know work is done. When orchestrator function wakes up, it will start from the beginning (not from where it left). It calls the activity function in step 2 again but before that goes to the execution history and checks if it was already done. It is returned as already done, so it skips the activity function an returns the output.We have Execution History (Has a history table)History Table Orchestrator Started Execution Started Task Scheduled, SayHello, .NET Orchestrator Completed Execution Completed, [“Hello .NET”] Orchestrator CompletedOrchestrator Constraints Orchestrator code must be deterministic. Never use random numbers, DateTime.UtcNow, Guid.NewGuid() etc. But we can use DurableOrchestrationContext.CurrentUtcDateTime Don’t write infinite loops. Use DurableOrchestrationContext.ContinueAsNew() Never do I/O directly in orchestrator. We can Do I/O in activity functionsMonitoring and Management Use Azure App Insights to monitor running instances and health. Function App also exposes HTTP API for management (status, update, terminate) Version your durable function consciously. Do nothing Wait for orchestrator to drain Side-by-side deployment (Update the name of your task hub on deployment) " }, { "title": "Stock Market Crash of 2008", "url": "/posts/stock-market-crash-2008/", "categories": "Blogging, Stock Market, Personal Finance", "tags": "stocks investing financial wealth", "date": "2022-06-29 16:40:00 +0530", "snippet": "IntroductionIn this blog, I’ll try to explain the events that led to the 2008-2009 financial crisis or the 2008 Stock Market Crash.The Great Recession of 2008The Great recession refers to the global economic trumoil that occurred between 2007 and 2009. This led to a loss of almost trillions of dollars and affected the lives of many people directly and indirectly. It led to a lot of people losing their jobs and investors loosing their investments. The global recession started in the United States during 2008. It began with the bursting of the United States housing bubble in 2005-2012. To understand what led to the housing bubble burst, we need to understand some complex macroeconomic terms. Let us try to understand them one by one and follow through to the entire story.Mortgage Backed Security (MBS)Securities refer to a tradable financial asset. For example in the case of stock market a stock is a security. For a company, it’s stock is backed by it’s fundamental value. Similarly, mortgage backed security refers to the security derived from mortgages (mortgages support or back this security). Mortgage is a term used to refer to home loans. This MBS or Mortgage Backed Securities were used as a financial asset by the investment bankers in the US. MBS was seen as a high fixed income low risk investment asset. To get a better understanding of how this was used as a financial asset, let’s take the following example.Suppose we have a large sum of money and want to invest it, some of the options available to us are either depositing it in an FD (low returns) or investing it in mututal funds or the stock market which is said to be high risk but gives a high return. It is during this time that a bank contacts us and says someone has taken a loan from this bank for building a house with his land as collateral. He has a good relationship with the bank and is said to repay the loan. There is a contract between the bank and this person where the person pays a fixed interest to the bank for a given time period. The bank proposes an investment option to us where the contact between the bank and this person will be transferred to us, but we have to pay the lumpsum amount that he has taken as loan to the bank. The amount paid by the person will be transferred to us (he will be paying an average interest of 10-12%). The banks benifit is the fees during the transactions and the amount paid as loan returned very easily.Applying this example to a large scale, where a bank gives home loans to a large number of credible people and collectively pool them into a security/contract and sell it to us as an investment option. The bank will also rate these loans through a credit rating agency. Bank gurantees that all these are AAA rated loans. Since there is a credible bank which only issues loans after doing all verification and a credit rating agency which cross checks it and gives it a rating, the security provided will be a very safe option for investing. Even if the loan somehow defaults (ie, the person doesn’t pay the loan) we have the property as collateral and the bank will sell this and pay back our investment money.Who came up with MBSThis idea of using Mortgage Backed Security was introduced by Investment Banks in the US. In the whole process the Bank which issues the loan can be termed as Lender. The person who invests the money is the Investor. The person who takes the loan is the Borrower. The whole process is facilitated by Investment Bankers. When the investment banks were analysing the market, they could see that there were a lot of lenders issuing loans. Once they issue the loan, the lender has to wait till it is repaid. So, instead of the loan sitting idle with the lender, the investment bankers came up with an idea of giving these loans to the investors and thereby generating benefits for both the investors and lenders and in this process some commission to the investment banks. The lenders benifited from this as once they sold the loan to the investment banks who inturn sold it to the investor, they would get the whole loan amount back and could issue another loan with this money. The retail investors saw a high income low risk investment opportunity in the MBS. Investment banks collected a fee from both the lender and investor thereby earning money.This was a win-win situation for everyone. However, like every good idea there were some chances of failure in this idea as well.How did the MBS CollapseIn the year 2000, there was a dotcom bubble burst in US which led to a crash of the stock market and a lot of companies went bankrupt. In the early 2000’s there were no investment oppportunities for retail investors as the stock market had crashed. The good investment option available were US treasury bills where investors could only get low interest rates. To revive the market, the interest rates issued by banks was reduced and thus a lot of people started taking loans to build houses. There was a housing boom in the early 2000’s as a lot of people started to build houses and the real estate prices went up. Retail investors saw the real estate as a good investment opportunity. Lenders could get more transactions as a lot of people were taking loans for building houses. Investment bankers identitied an opportunity in the increasing loans issues by lenders and the investment interest of retail investors in real estate. Investment bankers went to lenders and started purchasing the loans from them. They collected and pooled these loans to form Mortgage backed securities and started selling them to retail investors. Investment bankers benefited most from this opportunity. As more and more retail investors wanted to purchase MBS, the investment bankers introduced new something called CDO (Collateralized debt obligation).CDO is a financial security consisting of MBS, vehicle loans, personal loans etc. Even after issuing CDO’s the surge in retail investors wanting to invest in MBS did not stop. However, there were limited number of MBS. So the investment bankers went to the lenders and asked them to issue more loans, through which they could create more MBS and sell it to retail investors. Lenders would also only benifit from this so they started giving loans to everyone without doing proper background check, credit ratings, and whether the person would be able to repay the loan. Due to the pressure from investment bankers lenders started giving loans to ineligible people. This inturn led to low quality loans being pooled into MBS and being sold to retail investors. These low quality loans were termed as Sub Prime Loans. The credit rating agencies were paid by investment banks to give AAA rating to the sub prime loans. So, even very low quality loans were sold to retail investors as AAA rated loans. It was during this time that certain insurance firms came up with Credit Default Swap (CDS). Credit Default Swap was an insurance introduced on CDO’s and MBS’s by certain insurance and financial companies. People would pay a premium as insurance on the MBS and CDO’s purchased from investment bankers to insure them incase of failure. As MBS and CDO’s were seen as the most safe investment, the insurance companies never though that they would fail and thus would get a lot of profit by selling CDS. Companies like AIG started selling CDS. Some of the retail investors started buying CDS. Things went up even higher when people started using CDS as a trading instrument - based on how the prices of MBS and CDO’s moved people started betting using CDS. Billions of dollars started flowing through the market based solely based on these MBS and CDO’s. As time went by, most of the loans inside the MBS were sub prime loans that would default for sure. Most of the sub prime loans were issued on a variable rate of interest ie, the interest rate increases by each year. People were unable to repay these loans. In the 2007-2008 period, the loans started to default one by one so, the lenders sold the collateral ie, the property and started giving back the money to retail investors. But as the defaults started to increase, so did the number of houses to be sold. As the supply of houses to sell increased and demand stayed the same, this led to decrease in real estate prices. So, even after selling the houses they could not pay back the retail investors.As the prices of real estate started going down, the people who took large sums of loans to buy the houses could see that their house wasn’t worth the amount of loan taken to purchase them (Even selling the house couldn’t repay the loan). So a large amount of people started to stop repaying loans and this led to a large scale default of home loans/mortgages. Thus, the value of Mortgage backed securities went to 0. Retail investors lost 100’s of billions of dollars. The ones most affected by this were the investment banks who had purchased a large amount of loans to make the MBS and CDO’s. Even though they sold many of them to retail investors a large amount of the MBS holding were with investment banks. The money used to purchase loans from Lenders was also mostly other loans. The investment banks had a lot of outstanding loans and MBS assets which had 0 value. They had a liquidity crunch. The insurance companies who issued CDS also were affected as they had to pay the insured sum to the people who purchased the CDS because the MBS had failed. This was when the problems came to limelight and was identified as a major issue. It started affecting banks, investment banks, housing market etc. As the banking system crashed it started affecting the US economy as a whole. Banks couldn’t issue loans and thus businesses were affected. This led to the stock market crashing and people going jobless and homeless. The US economy crashed and thereby led to a global recession.ConclusionIn simple terms, a person wanting to build a house took a housing loan from a bank. Seeing this process as profitable to many instruments, a lot of things like MBS, CDO, CDS were derived from these loans. These became the biggest things in the economy. A failure to pay back the loan led to the collapse of all the things related to this. Imagine this on a large scale and that is how the housing market bubble burst in the 2008 thereby leading to a global recession." }, { "title": "Microsoft Azure Fundamentals", "url": "/posts/azure-fundamentals/", "categories": "Blogging, Programming", "tags": "development programming cloud azure", "date": "2022-06-16 14:10:00 +0530", "snippet": "IntroductionThis blog contains the concepts of Microsoft Azure Fundamentals required to take the AZ-900 certification exam.Cloud Concepts (20-25%) [MODULE - I]Cloud computing is the delivery of computing services over the internet, enabling faster innovation, flexible resources, and economies of scale. Resources can be provisioned and released very easily.Cloud ModelsThere are different cloud models: Public cloud It is owned by cloud services or hosting providers. They provide resources and services to multiple organizations and users. Users access via secure network connection. (over the internet) No need of deep technical skill to use the public cloud. Private cloud It is owned by an organization. Limited to that organization and they are responsible for purchase of hardware, network, updates, security, etc Organizations create a cloud environment in their datacenter. Organization is responsible for operating the services they provide. Does not provide access to users outside the organization. Hybrid cloud Combination of public and private clouds. Deep techincal skills are required to operate the private cloud and ensure that both clouds can operate together efficiently. Public Cloud Private Cloud Hybrid Cloud Organizations pay only for what they use in the cloud Organizations are responsible for hardware maintenance and updates Organizations control security, compliance, or legal requirements Is available to the public No access to the public Services running on public cloud is accessible to anyone No capital expenditures are necessary to scale up resources Hardware must be purchased for start-up and maintenance Most flexible cloud Applications can be quickly provisioned and deprovisioned Organizations have complete control over resources and security Organization determines which application will run where Cloud benifits and considerationsSome of the main benifits of moving to the cloud are: High availability - Ability to keep resources up and running for long periods of time with very little down time. Scalability - Scaling out/in (horizontal scaling) this means adding more resource/servers/VM’s as you need them.Scaling up/down (vertical scaling) - adding to existing resources either by adding more CPU/memory. Global reach - Being able to access and put the resources around the world. Agility - Ability to react quickly to work load demands. Allocate more resources based on demand. Fault tolerance - Ability to remain up and running if a service or component has a failure or is no longer working. Elasticity - Similar to scalability. Ability to automatically increase/decrease resources as needed. Customer latency capabilities - The server needs to be as close to the customers as possible to reduce the latency for them accessing resources. With global reach, we can put the resources as close to the customers as possible. Predictive cost considerations - We can quote how much we are going to spend before actually spending it.Expenditure ModelsCapital Expenditure (CapEx) Up-front spending of money on physical infrastructure. Building inhouse data centers is a CapEx model. (We need to buy land, buy physical resources etc) Costs from CapEx have a value that reduces over time.Operational Expenditure (OpEx) Spending and billing of services or products as needed. This is the model used in cloud. Expenses are deducted in the same year.Consumption-based model - (pay as you consume)It is another huge benifit of the cloud.Cloud service providers operate on a consumption-based model, which means the end users only pays for the resources that they use. Whatever they use is what they pay for. Better cost prediction. Prices for individual resources and services are provided. Billing is based on actual usage.Cloud servicesThere are three cloud service models: IaaS - (Infrastructure-as-a-Service) PaaS - (Platform-as-a-Service) SaaS - (Software-as-a-Service)We can use a combination of these services based on requirements. eg:- We can use Microsoft 365 for the company’s computer which is SaaS. In Azure we can host our VM’s which is an IaaS model. We can use Azure SQL database which is a PaaS model. Infrastructure as a Service (IaaS)Build pay-as-you-go IT infrastructure by renting servers, virtual machines, storage, networks, and operating systems from a cloud provider.Paying for resources as you need them. Renting VM’s and servers on the cloud and paying by what you actually use.eg:- We rent servers and storage, firewall and security, renting physical datacenter or the building and we put all the resources on top of that. We can load VM’s, storage, OS etc from the cloud solution provider. Platform as a Service (PaaS)The cloud solution provider is responsible for everything apart from the customers own application. They manage the server, infrastructure, OS, network, and even the service configuration.Provides an environment for building, testing, and deploying software applications; without focusing on managing underlying infrastructure. Allows the company to be more efficient and productive. Software as a Service (SaaS)Users connect to and use cloud-based apps over the internet.eg: Microsoft Office 365, email, and calenders Renting the software on monthly/yearly basis. The software provider will take care of everything else the server, OS, networking, infrastructure, hosted apps, etc Sharing Responsibility ModelAs per the below table, for private cloud, the user is responsible for managing all the things from storage to Data &amp;amp; access.In case of IaaS, Microsoft manages compute, networking and storage which is the physical hardware.In case of PaaS, the customer focuses on their applications and data. Microsoft manages the infrastructure underneath.In case of SaaS, the customer manages data and access, Microsoft manages everything else. On-Permises (Private Cloud) IaaS PaaS SaaS Data &amp;amp; Access Data &amp;amp; Access Data &amp;amp; Access Data &amp;amp; Access Applications Applications Applications Applications Runtime Runtime Runtime Runtime OS OS OS OS VM VM VM VM Compute Compute Compute Compute Networking Networking Networking Networking Storage Storage Storage Storage Core Azure Services (15-20%) [MODULE - II]Azure Architectural ComponentsRegionsAzure offers more global regions than any other cloud provider.It has 60+ regions representing over 140 countries. Regions are made up of one or more datacenters in close proximity. They provide flexibility and scale to reduce customer latency. Preserve data residency with a comprehensive compliance offering. Select region close to us for low latency.Region PairsTwo regions in same geography seperated by atleast 300 miles is called region pairs. At least 300 miles of separation between region pairs. Automatic replication for some services. Prioritized region recovery in the event of outage. Updates are rollout sequentially to minimize downtime.Availability ZonesThey are in seperate data centers.There are also availability sets - They are within the same data center.Both are used to protect from failures.Availability zone - protect from data center failure.Availability set - protect from hardware failures within an auzre data center. Provide protection against downtime due to datacenter failure. One Azure region can have multiple availability zones (upto 3). Physically separate datacenters within the same region. Each datacenter is equipped with independent power, cooling, and networking. Connected through private fiber-optic networks for very low latency between them.Availability OptionsIn the cloud there is a lot of flexibility to plan for backup and resiliency in case of a data center failure or other issues. We should get high 9 availability.VM’s have SLA’s of 99.99%. The higher the SLA, the better.Single VM - 99.9%Availability zones - 99.99%Region Pairs - highest SLACore Azure ResourcesAzure resources are components like storage, virtual machines, and networks that are available to build cloud solutions.eg: - Virtual Machines, Storage accounts, Virtual networks, App services, SQL Databases, Azure FunctionsThe main types of Azure resources are: Compute Networking Storage DatabasesResource GroupsA resource group is a container to manage and aggregate resources in a single unit. Grouping the resources into a logical group by project type/ project life cycle. So when the project is over, we can de-allocate the resources in that resource group. Resources can exist in only one resource group. Resources can exist in different regions. Resources can be moved to different resource groups. Applications can utilize multiple resource groups.Azure Resource Manager (ARM)ARM provides a management layer that enables you to create, update, and delete resources in your Azure subscription. It enables to automatically deploy and configure resources using different automation and scripting tools like azure powershell, azure cli, azure portal, rest API, and client SDKs. Automation helps maintain consistency and standards across deployments.Azure SubscriptionsAn Azure subscription provides you with authenticated and authorized access to Azure accounts. Billing boundary: Generate seperate billing reports and invoices for each subscription. Access control boundary: Manage and control access to the resources that users can provision with specific subscriptions.Azure portalAzure compute servicesAzure compute is an on-demand computing service that provides computing resources such as disks, processors, memory, networking, and operating systems.eg: VM, App services, Container instances, Azure kubernetes services, Windows Virtual Machines. Azure Virtual MachinesAzure virtual machines (VM) are software emulations of physical computers. They include a virtual processor, memory, storage, and networking. VM is an IaaS offering that provides total control and customization.Virtual machine scale sets allows to automatically manage fluctuations and workloads in the cloud. (Elastic benefit discussed earlier) Another type of computing resource is serverless computing. It is different from VM’s and doesn’t require storage and an OS. They run as needed when needed.eg: Azure App Service, Azure functions, Azure logic Apps Azure App ServicesAzure app services is a fully managed platform to build, deploy, and scale web apps and API’s quickly. Works with .NET, .NET Core, Node.js, Java, Python, or PHP PaaS offering with enterprise-grade performance, security, and compliance requirements. Azure FunctionsSmall pieces of code that can be launced without worrying about the application infrastructure. A function is triggerred by a specific type of event such as changes in data, responding to messages, running on a schedule etc. They are designed for short run and are little tasks that are stateless. Azure Logic AppsAzure Logic apps provide automated access and data across the cloud without writing code. Every logic app workflow starts with a trigger which fires when a specific event happens or when new data becomes available. The above 2 tools Azure Functions and Logic Apps run instantly in short bursts.Azure Container ServicesAzure containers are a light-weight, virtualized environment that does not require operating system management like VM’s, and can respond to changes on demand. Azure Container InstancesA PaaS offering that runs a container in Azure without the need to manage a VM or additional services. Can be event driven or long running. Azure Kubernetes ServiceAn orchestration service for managing containers with distributed architectures and large volumes of containers. When the app grows, we will get multiple containers across different servers, we can use AKS for managing them. Windows Virtual DesktopIt is a desktop and app virtualization that runs in the cloud. It helps to replace physical computers and can enable companies to purchase virtual desktops to it’s employees and this can be managed remotely. Create a full desktop virtualization environment without having to run additional gateway servers. Publish unlimited host pools to accomodate diverse workloads. Reduce costs with pooled, multi-session resources. Azure Networking Services Azure Virtual Networks (VNet)Enable many type of Azure resources like VM’s to securely communicate with each other, the internet, and on-premises networks. A Virtual Network is scoped to a single region however, multiple Virtual networks from different regions can be connected together using virtual network peering. Virtual Private Network Gateways (VPN)It is a distinct type of Virtual network gateway that sends encrypted traffic between an Azure virtual network and an on-premises location over the public internet. It provides a more secure connection from on-premises to azure over the internet. Azure Express Route It is a dedicated private connection from on-premises network to azure through a direct link that is setup with the connection provider. It is expensive and meant for large enterprise customers. Azure Database Services Azure Cosmos DatabaseIt is a globally distributed database service that elastically and independently scales throughput and storage. It is a NoSQL database. It is the first and only service to offer five 9’s SLA. 99.999% SLA Azure SQL DatabaseIt is a relational database as a service (DaaS) based on the latest stable version of the Microsoft SQL Server. Azure Database for MySQLIt is a fully managed MySQL database service for app developers. Azure Database for PostgreSQLIt is a relational database service based on the open-source Postgres database engine. Azure Database Migration ServiceA database migration service is a fully managed service designed to enable seamless migrationsfrom multiple database sources to azure with minimal downtime. Azure SQL Managed InstanceMany organizations have SQL database on premises. We can move them into the cloud without touching the code, structure, and security. This SQL database will run the same software and will be managed, patched, and maintained by azure. This is done by Azure SQL Managed instance.It allows existing SQL Server customers to lift and shift their on-premises applications to the cloud with minimal application and database changes. Fully managed and evergreen platform as a service. Preserves all PaaS capabilities (automatic patching and version updates, automated backups, and high availability) all these drastically reduce management overhead in TCO. (total cost of ownership) Exchange existing license for discounted rates on SQL Managed Instance using the Azure Hybrid Benefit. It has a 99.9 uptime. Azure MarketplaceIt is the place where customers can find, try, purchase, and provision applications and services from hundreds of leading service providers, which are all certified to run on Azure. Open source container platforms VM and database images Application build and deployment software Developer tools Over 10,000+ listings Azure Core Solutions and Management Tools (10-15%) [MODULE - III]Azure Internet of ThingsInternet of things (IoT) is the ability for devices to garner and then relay information for data analysis. Azure IoT CentralIt is a fully managed global IoT SaaS solution that makes it easy to connect, monitor, and manage IoT assets at scale. Azure IoT HubIt is central message hub for bi-directional communiation between IoT applications and the devices it manages. It is a managed service hosted in the cloud. Azure SphereA comprehensive IoT security solution including hardware, OS, and cloud components.It is a secured, high-level application platform with built-in communication and security features for internet connected devices. Azure Big data and analytics Azure Synapse AnalyticsA cloud-based enterprise data warehouse. Azure HDInsightA fully-managed, open-source analytics service for enterprises. It is analytics at large scale. Enables to create clusters like apache hadoop, apache kafka, apache storm etc Azure DatabricksA collaberative Apache Spark based analytics service. Support Python, R, Java, SQL etcAI &amp;amp; Machine Learning Azure Machine LearningCloud-based to develop, train, and deploy machine learning models. Machine learning Studio. (drag and drop service) Cognitive ServicesQuickly enable apps to see, hear, speak, understand, and interpret a user’s needs. Azure Bot ServiceTo create intelligent bots.Develop intelligent, enterprise-grade bots.Azure Devops and GitHub Azure DevOpsDevelopment in collaboration tools including azure repos, pipelines, kanban boards, and automated cloud-based load testing. GitHubProvides hosting for software development and version control using git. GitHub Actions for AzureAutomation tools to build workflows from github to azure automatically using opensource devops repository. Helps to automate software workflows to build, test, and deploy from within GitHub. Azure DevTest LabsQuickly create environments in Azure while minimizing waste and controlling cost.Azure Management Tools Azure Portal Azure PowerShell: set of commandlets that allow to manage azure resources directly from the powershell command. Azure Mobile App: Diagnose and fix issues. Can run commands from the mobile apps. CLI: cross platform command line program that connects azure, executes admin commands on azure resources. Azure REST API: Azure Cloud Shell : browser based scripting environment in the azure portal. Provides flexibility. Offers powershell and bash. Azure Resource Manager (ARM): Allows automatic creation of resources using scripting tools like powershell, cli, rest api etc Everything done through the azure portal UI can be done using powershell/bash. Like creating VM, Resource etc.Azure Resource Manager (ARM) templatesThese templates are JSON files that can be used to create and deploy Azure infrastructure without having to write progamming commands.Azure AdvisorMicrosoft takes a look at the deployed resources and makes recommendations based on best practises in categories like Reliability Security Performance Cost Operational ExcellenceService HealthHealth of azure resources and data centers around the world. Can filter by subscriptions, region, service. We can see planned maintenance, health history etcAzure MonitorAs soon as we launch a resource in azure like a VM, azure collects metrix and log information. Metrix will say how the resources are performing and logs record when the resource is created or modified. Metrix will tell us how the resource is performing, how much it is consuming. (network bandwidth) Application insights Log analytics Smart alerts Automation actions Customized dashboardsAzure General Security and Network Security (10-15%) [Module - IV]Azure Security Tools &amp;amp; FeaturesTo protect ourselves globally using Azure, we can use Azure security center and Azure Sentinel.Azure Security CenterIt is one of the best tools in azure. Azure Security Center is a monitoring service that provides threat protection across both Azure and on-premises datacenters.It provides continous monitoring. Provides security recommendations Detects and blocks malware Analyze and identify potential attacks Just-in-time access control for ports which helps reduce service attacks. (Only allows required traffic)Has: Free Tier (Comes with basic subscription) Standard Tier (has advanced security) [Only standard tier supports on-premise env] It provides an overall policy and compliance security score for selected directory and subscriptions.It is the hub for all security related stuff.With the security center we get: Policy Compliance - Run policies across management groups, subscriptions, or tenants. Continuous Assessments - Assess new and deployed resources to ensure that they are configured properly. Tailored Recommendations - Recommendations based on existing workload with instructions on how to implement them. Threat Protection - Analyze attempted threats through alerts and impacted resource reports.Azure SentinelIt is a birds eye view across your entire enterprise.Azure Sentinel is a security information management (SIEM) and security automated response (SOAR) solution that provides security analystics and threat intelligence across an enterprise. Helps in threat protection using AI and automatic response.Connector and integrations: Office 365 Azure Active Directory Azure Advanced Threat Protection Microsoft Cloud App SecurityAzure Key VaultIt is a centralized location in azure where we can store certificates, keys, application secrets etc. We can control who has access to and what permission to this. We also have a log of who access it and when. If we have any control access tokens, API secrets etc we can store them in the Azure Key Vault. Key Vault can be integrated with other services like storage. Secret Management Key Management Certificate Management Storing secrets backed by hardware security modules (HSMs)Azure Dedicate Host (This entire host will be for your subscription)It provides physical servers that host one or more Azure VM’s that is dedicated to a single organization’s workload.(Single azure subscription)Benefits of having a dedicated host: Hardware isolation at server level. (No other VM’s will be deployed here other than your’s) Control over maintenance event timing. Aligned with Azure Hybrid use benefits. Virtual scale sets are not supported in dedicate hosts. Scale sets support up to 1,000 VM instances Azure Network SecurityDefense in depthThis is a strategy that employs a series of mechanisms that are designed to slow the advance of an attack. A layered approach to securing computer systems. Provides multiple levels of protection. Even if one layer gets breached, there are other layers. Attacks against one layer are isolated from subsequent layers.This layered approach is implemented in both the physical data centers and the services inside azure.The layers are physical security, Identity &amp;amp; Access, Perimeter, Network, Compute, Application , and Data at the last layer.Shared SecuritySecurity is a shared responsibility between customer and cloud provider. In an on-premise data center the customer is responsible for everything.In an IaaS model, azure is only responsible for the physical datacenter, network, and hosts/OS. You are responsible for the security for rest of the systemIn PaaS, azure takes care of the physical systems, the OS, underlaying software. Rest is handled by customer. Application protection is shared by both parties here.In SaaS, almost everything is secured by azure. There is shared responsibility for Identity and directory infrastructure.In all the models, the customer is responsible for securing:- Data governance and rights management Client endpoints Account and access managementHow to protect the network layer in the Defense in depth:Network Security Groups (NSGs)NSGs filter network traffic to and from Azure resources on Azure Virtual Networks. Set inbound and outbound rules to filter by source and destination IP address, port, and protocol. Add multiple rules, as needed within subscription limits. Azure applies default, baseline security rules to new NSGs. Override default rules with new higher priority rules. We cannot delete rules. We can set priority level with a number, the higher value will have more priority. No 2 rules can have same priority.How to protect the perimeter layer in the Defense in depth:Azure FirewallIt is a fully managed cloud based network security service to protect virtual network resources. A stateful, managed Firewall as a Service (FaaS) that grants/denies server access based on originating IP address, in order to protect network resources. Applies inbound and outbound traffic filtering rules (http,https,ftp,rdp) Built-in high availability Unrestricted cloud scalability Uses Azure Monitor loggingAzure Application Gateway also provides a firewall, Web Application Firewall (WAF). WAF provides centralized, inbound protection for your web applications. It is a load balancer that includes a web application firewall.Azure DDoS protectionA Distributed Denial of Service attack is when there is an overwelming amount of traffic send to azure network or resource, making apps slow or unresponsive.Azure firewall just checks allowed and not allowed traffice, but DDoS protection checks if the traffic is valid. It prevents any unwanted traffic from coming in.Two tiers:- Basic Service tier (It is automatically enabled in Azure) Standard Service tier - adds mitigation capabilities that are tuned to protect Azure Virtual Network resources.Attacker –&amp;gt; Azure backbone –&amp;gt; Azure DDoS Protection –&amp;gt; Virtual NetworkReviewing Defense in DepthCombining network security solutions NSGs with Azure Firewall to achieve defense in depth Perimeter layer protects your network boundaries with Azure DDoS protection and Azure Firewall Networking layer only permits traffic to pass between networked resources with NSG inbound and outbound rules. Network layer protection - Network Security Groups Perimter layer protection - Firewalls and DDoS protectionIdentity, governance, privacy, and compliance (20-25%) [Module - V]Azure Identity ServicesAuthentication vs Authorization Authentication Authorization Identifies the person or service seeking access to a resource (username,pwd) Determines an authenticated person’s or service’s level of access (Permission they have) Requests legitimate access credentials Defines which data they can access, and what they can do with it Basis for creating secure identity and access control principles   Azure MFA’s (Multi-Factor Authentication)It provides additional security for your identities by requiring two or more elements for full authentication. Azure only supports something that you know and something that you possess types of MFA’s (see below). It doesn’t support biometrics (something that you are) Something you know (Username, password, security question) Something you possess (Mobile app like authenticator) Something you are (Face scan, finger print scan)Azure Active Directory (AAD)It is Microsoft Azure’s cloud-based identity and access management service. It can be used for external resources like Office 365, Azure portal etc.Azure Active Directory can be used for:- Authentication (employees sign-in to access resources) Single Sign-On (SSO) (sign in with a single click to access multiple resources) Application management (AAD can manage cloud and on-premise apps) B2B (Manage vendors in the app) B2C identity services (Manage guest users in the app) Device management (How cloud access corporate data)Conditional AccessIt is used by AAD to bring signals together to make decisions and enforce organizational policies. What data users can access based on their location, device, etc.Conditional access uses AAD to make decisions based on organizational policies.The signals are:- User or Group Membership IP Location Device Application Risk Detectioneg: Need to login from corporate device from corporate network, then can access data.Conditional access is a great tool within AAD.Azure governance featuresRBAC (Role-based access control)Provides fine-grained access management for azure resources which gives admin control to grant rights that the user needs to do his job.Enables access to azure portal and controlling access to resources.RBAC is included in all azure subscriptions (No additional price). Only grant necessary permissions to users. This can be applied at the subscription level, management group level, resource group level or for individual resources.Some of the different roles are: Owner (All permissions) Contributor (can’t change roles) Reader (view permission only)We can also create new roles if necessary.Resource locksAs we add owners, contributors, readers, editors etc (ie, different roles). Resource locks help to prevent accidental deletion or modification of Azure resources thus protect resources.It manages locks at subscription, resource group, or individual resource levels within Azure portal.Locktypes: Read-Only (We can read but can’t update or delete) It is read only. Can’t insert/update/delete Delete (Least restrictive - we can read, update but cannot delete)Adding a lock is a great governance tool.TagsProvides metadata for azure resources. It is a great tool when it comes to reporting, billing etc. Logically organizes resources into a taxonomy. Consists of a name-value pair. Very useful for rolling up billing information. Tags don’t have parent child relationships. We can have upto 50 tags per resourceAzure PolicyAzure policy helps to enforce organizational standards and to access compliance at-scale. Provides governance and resource consistency with regulatory compliance, security, cost, and managements.This helps to prevent users from selecting a really expensive VM or how to prevent users from selecting things that don’t meet company standards. Deploy in certain regions only. These can be done using Azure policy. We can set the orgainzational standards and the policy will automatically enforce this across our subscriptions.There are buit-in policy and initiative definitions under categories such as storage, networking, compute, security center, and monitoring. Each blueprint can consist of zero or more ARM template artifactsAzure BlueprintsAzure blueprints makes it possible for development teams to rapidly build and setup up new environments. Development teams can quickly build trust through organizational compliance with a set of built-in components (such as networking) in order to speed up development and delivery.It makes a blueprint of your azure environments. Very helpful for devops. They are different from ARM templates. When you deploy an ARM template, there is no relation between the deployed resource and where it came from. With Azure blueprint, the blueprint is related to the deployed resource. Role assignments Policy assignments Azure Resource Manager(ARM) templates Resource GroupsCloud Adoption Framework (CAF)This is a great tool if you are new to azure. Helps in cloud adoption. It shows the best practices from Microsoft employees, partners, and customers. Tools, guidance, and narratives for strategies and outcomes.It is the Microsoft approach to implementing Azure.Azure privacy, compliance, and data protection standardsSecurity, privacy and compliance are the foundation of everything done in Microsoft.1. Security: Secure by design. Built in intelligent security, Microsoft helps to protect against known and unknown cyberthreats, using automation and AI.2. Privacy: Committed to ensuring the privacy of organizations through contractual agreements, and by providing user control and transparency.3. Compliance: Microsoft respects local laws and regulations and provide comprehensive coverage of compliance offerings.Compliance Terms and RequirementsAzure provides most comprehensive set of compliance offerings (including certifications and attestations) of any cloud service provider. Some of the compliance offering include: CJIS HIPAA CSA STAR Certification EU Model Clauses ISO/IEC 27018 NISTAzure compliance DocumentationMicrosoft offers a comprehensive set of compliance offerings to help organizations comply with national, regional, and industry specific requirements that govern the collection and use of data. It has Global, US Government, Industry, and regional offerings.Privacy statementsProvides opennes and honesty about how Microsoft handles the user data collected from its products and services. The Microsoft privacy policy explains: What data Microsoft processes How Microsoft processes it What purposes the data is used forOnline service terms and Data protection AddendumOnline Services Terms: The licensing terms define the terms and conditions for the products and online services you purchase through microsoft volume licensing programs.Data Protection Addendum: The DPA sets forth the obligations, with respect to the processing and security of Customer Data and Personal Data, in connection with the online services.Trust CenterThis is the home base of everything related to privacy, compliance, and trust. It has a lot of information for business managers, admins, engineers, privacy officers, and legal teams.Access trust center hereAzure Sovereign Regions (US Govt services)This is a completely seperate physical instance of Azure. It meets all the security and compliance needs of US federal agencies, state and local governments, and their solution providers. It is physically isolated from non-US govt. deployments. Accessible only to screened, authorized personnel.Azure Sovereign Regions (Azure China)Microsoft is China’s first foreign public cloud service provider, in compliance with govt. regulations. It is physically seperated from other Azure instances and is operated by 21Vianet. All data stays within China to ensure compliance.Azure pricing and lifecycle (Cost management and Service level agreements) (10-15%) [Module - VI]Methods for managing costsFactors affecting costsThere are 6 primary factors affecting costs:Resouce type, services and location have definite direct impact on cost Resource TypeCosts are resource-specific, so the usage that a meter tracks and the no. of meters associated with a resource, depend on the resource type. ServicesAzure usage rates and billing periods can differ between Enterprise, Web Direct, and CSP(Cloud solution providers) customers. If third party is managing our Azure, we have to pay their cost also. LocationThe Azure infrastructure is globally distributed, and usage costs might vary between locations that offer Azure products, services, and resourceseg: Switzerland costs more to run a data center there. So cost here is high. East US is low. BandwidthDepending on how data transfers are going, there is billing by zone. Different geographies are organized into Zones. Weather or not you have outbound or inbound data transfers outside your Zone, there can be additional charges.eg:- West US –&amp;gt; Australia (will cost outbound changes) Reserved InstancesWith this we can save money. Reserving resources for one or three year plans can help reduce resource costs upto 72% on pay-as-you-go prices. Azure Hybrid Use BenefitThis allows to use on-premises licenses on Azure at a reduced cost. We can bring licenses from on-premise to Azure.Pricing CalculatorIt is a tool that helps to estimate the cost of Azure products. The options in pricing calculator include Region, Tier, Billing options, Support options, Programs and offers, Azure dev/test pricing.Total Cost of Ownership CalculatorA tool to estimate cost savings you can realize by migrating to Azure cloud.A report compares the costs of on-premises infrastructure with the costs of using Azure products and services in the cloud.Azure Cost ManagementIt allows to look at billing reports. We can drill down deeper if we’ve used tags. If we have budgets, you can use it to not let subscriptions go over certain spend. We can also setup alerts that will alert the managers or anyone incharge of the project as we approach the budget. Reporting Data enrichment Budgets Alerting RecommendationMinimizing Costs - Options to reduce and control costs Perform - Perform cost analysis. Use Azure Pricing &amp;amp; TCO calculators Monitor - Monitor usage with Azure Advisor. Implement recommendations. Use - Use spending limits Use - Use Azure reservations and Azure Hybrid Benefit (HUB) Choose - Choose low-cost locations and regions Keep - Keep up-to-date with latest Azure customer and subscription offers Apply - Apply tags to identify cost owners. Identify usage owners with tagsService Level Agreements and Service LifecyclesAzure Service Level Agreement (SLA)SLAs describe Microsoft’s commitments for uptime and connectivity. When we deply a particular Azure service, there is a SLA. It is a contractual obligation that Microsoft is commiting that this service will be up and running a minimum time per month. If the service is down beyond the agreed time, then a credit is given to the user. Free and preview features don’t offer SLA. SLA’s are based on individual products and services.SLA’s for Azure products and servicesPerformance targets are expressed as uptime and connectivity guarantees. Performance-targets range from 99% to 99.999%. If a service fails to meet the guarantees, a percentage of the monthly service fees can be credited. The higher the SLA, the maximum downtime you will experience per month goes down eg: For SLA 99.999%, downtime is only 26sFactors impacting SLAsThe more services we add to the solution, the more complex it gets. As it becomes more complex, the SLA will go down. Free services and preview features don’t have SLA’s. We can increase SLA using availability zones and redundant systems. Composite SLA refers to SLA for service with multiple components/resources. The composite SLA can be calculated by multiplying the SLA for each resource. Lower your SLA Raise your SLA Adding more services Availability Zones Choosing free or non-SLA services Redundant systems Azure preview program and feature lifecycle (public preview –&amp;gt; GA)With Azure previews, users can test beta and other pre-release features, products, services, software, and regions to provide feedback Public Preview: All azure customers can evaluate the new features Generally available (GA): After public preview is completed, all customers can use the feature, and region availability will vary.Never use preview features in production. They also don’t have SLA’sMonitoring service and feature updatesAzure updates provides information about the azure products, services, and features in addition to product roadmaps and availability.View details about all Azure updates and their status Browse and search for updates Subscribe to Azure update notifications by RSS" }, { "title": "Data Structures and Algorithms in C#", "url": "/posts/data-structures-and-algorithms/", "categories": "Blogging, Programming", "tags": "development programming dsa c# dotnet6", "date": "2022-06-01 19:40:00 +0530", "snippet": "IntroductionAbstract Data TypeAn abstract data type is a class. Data structures are classes that are storing data and acting on it.Classes contain representation of data and operation on data.Big-O NotationThis determines how efficient a piece of code is. It is a way to describe the speed or complexity of a given algorithm. O(1) - “Constant” time complexity. It means the code is the most efficient.Some examples of constant are: Assignments var test = 0; Declaration var test; Arithmetic 2 + 2 Comparison 2 &amp;gt; 1 Accessing Element array[1]; Calling Function someFunction(); O(n) - “Linear” time complexity. Here as the values of n increases, the time taken to execute the program goes up in a linear fashion.Some examples of Linear are: Some type of iteration like for loop, while loop etc int total = 0; O(1)int i = 2; O(1)while (i &amp;lt;= 10) O(n){ total = total + i; i++;} If we have a program with code having O(1) and O(n) complexities, we take the higher no. Thus it being O(n) O(n^2) - “Quadratic” time complexity. If the algorithm is O(n^2), then it will have horrible performance. It is also called brute force.A quadratic algorithm is a : Nested for loops var n = int.Parse(Console.ReadLine());for (var r = 1; r &amp;lt;= n; r++){ for (var c = 1; c &amp;lt;= n; c++) { Console.Write(&quot;*&quot;); } Console.WriteLine();} log(n) n log(n)ArraysArrays store elements in contiguous (next or together in sequence) memory locations.Arrays can contain anything of same type with a fixed size.Arrays are very fast at GET and SET (data retrieval and setting)Lists&amp;lt;&amp;gt; in C# are actually arrays.The main things regarding arrays are inserting values into it (push) and deleting values from it (pop). Insertion 1.1 Inserting value at the start of an array ``` int[] intArray = new int[6]; //Make a variable to keep the length because length is based off capacity and doesn&#39;t // track the actual index. int length = 0; //Set values to array till index 2 for (int i = 0; i &amp;lt; 3; i++) { intArray[length] = i + 1; length++; } //for (int i = 3; i &amp;gt;= 0; i--) { // this is moving over all the values intArray[i + 1] = intArray[i]; } intArray[0] = 20; ``` 1.2 Inserting value at the end of an array ``` int[] intArray = new int[6]; //Make a variable to keep the length because length is based off capacity and doesn&#39;t // track the actual index. int length = 0; //Set values to array till index 2 for (int i = 0; i &amp;lt; 3; i++) { intArray[length] = i + 1; length++; } // Add value to end of the array intArray[length] = 8; length++; ``` 1.3 Inserting value anywhere in an array ``` int[] intArray = new int[6]; //Make a variable to keep the length because length is based off capacity and doesn&#39;t // track the actual index. int length = 0; //Set values to array till index 2 for (int i = 0; i &amp;lt; 3; i++) { intArray[length] = i + 1; length++; } for (int i = 3; i &amp;gt;= 2; i--) { // Shifting each element one position to the right intArray[i + 1] = intArray[i]; } intArray[2] = 34; ``` Deletion 2.1 Deleting value from the end of an array ``` int[] intArray = new int[9]; int length = 0; for (int i = 0; i &amp;lt; 6; i++) { intArray[length] = i + 1; length++; } length--; for (int i = 0; i &amp;lt; length; i++) { Console.WriteLine(intArray[i]); } ``` 2.2 Deleting value from the start of an array ``` int[] intArray = new int[9]; int length = 0; for (int i = 0; i &amp;lt; 6; i++) { intArray[length] = i + 1; length++; } for (int i = 1; i &amp;lt; length; i++) { intArray[i - 1] = intArray[i]; } length--; for (int i = 0; i &amp;lt; length; i++) { Console.WriteLine(intArray[i]); } ``` 2.3 Deleting value from anywhere in an array ``` // Delete value at 4th position for (int i = 0; i &amp;lt; 6; i++) { intArray[length] = i + 1; length++; } for (int i = 4; i &amp;lt; length; i++) { intArray[i - 1] = intArray[i]; } length--; for (int i = 0; i &amp;lt; length; i++) { Console.WriteLine(intArray[i]); } ``` Linear Search ArrayIn linear search we use a for loop to loop through the array and a conditional to return true oncethe element is found. It traverses the element in an orderly fashion from 0th index to the last index.// key refers to the value we are searching forbool LinearSearch(int[] array, int key){ for (int i = 0; i &amp;lt;= array.Length; i++) { if (array[i] == key) return true; } return false;}Linked List in C#It is the ancestor of Lists&amp;lt;&amp;gt; in c#.Arrays are fixed. We cannot insert values into the middle of an array without it being very expensive to do so.We can insert anywhere into a linked list and it’s dynamic.Insertions into Linked list have a time complexity of O(1). Best performanceStacks in C#Stack follows Last In First Out method. The last element inserted will be on top of the stack and will be the first oneto go out.Push - Add a new elementPop - Remove an elementPeek - Fetch the element present at the top of the StackInsertion into stack has a time complexity of O(1)Queues in C#Queues follows First In First Out method.EnqueueDequeue" }, { "title": "Basic Authentication", "url": "/posts/basic-authentication/", "categories": "Blogging, Programming", "tags": "development programming dotnet6", "date": "2022-05-24 13:40:00 +0530", "snippet": "IntroductionIn this blog, we’ll discuss about how we’ll store passwords in a database, the basics of authentication and jwt tokens. Authentication is verifying that the user is who he says he is.How to Store passwords in a databasePassword can be saved in different ways : Storing in clear text - Never save password in clear text Hashing the password - Apply a hashing algorithm to the password and storing the passwordhash in the database. You can’t calculate what the password is from the hash. However, if there are 2 people with the same password then the hashes of both these passwords will be the same. If the db is compromised, the hacker can identify that both passwords are same and decrypt them via the dictionary of hashes that have already been decrypted. Hashing and salting the password - A salt applied to a hashing algorithm will scramble the hash. So even if 2 passwords are the same, the password hash created will be different. We also have to store the password salt in the database to decode the hash (unscramble the hash).Simple basics authentication is implemented using password hash and salt. This is similar to the method followed in ASP.NET Identity however, it’s not as battle hardened as Identity.JWT Token AuthenticationAn API is not something that we maintain a session state with. We make a request to an API, it returns the data we asked for and that ends the relationship with the API. Tokens are good to use with an API, they are small enough to send with each request.JWT is an industry standard for tokens. They are self contained and can contain credentials, claims, and other information.JWT has 3 parts each seperated by a ‘.’ period Header - It contains the algorithm and token type. The algorithm is used to encrypt the signature. The type of the token will be JWT Payload - It contains information like claims, credentials etc. - (Roles, name identifies). It has 3 timestamps notbefore(nbf), expairy(exp), issued at(iat) Signature - This signature is encrypted by the server using a private key. The only part of the token that is encrypted is the signature.We cannot modify the token and expect the API to accept it. This will change the entire structure of the token and signature won’t be verified.The header and payload part of a JWT token can be decoded hereWorking: A user logs in and sends their username and password to the server The server validates their credentials and returns a JWT token that the client will store locally on their machine. (We use browser storage to store the token) JWT stored in the local machine (browser storage) is send along with all further requests. Anytime we want to access something that is protected by authentiation on the server, we send the JWT token with the request. We add an authentication header to the request and then the server will verify that the token is valid. The server will have the private key that was used to encrypt the signature and can use this to verify that the token is valid (since it’s stored in the server user secrets, no need for a database call) Server verifies the JWT and sends back response.Benifits of JWT: No sessions to manage - JWT’s are self contained tokens. Portable - A single token can be used with multiple backends. (Backends all share same private key) No cookies required - mobile friendly (Mobile phones don’t have cookies) Performance - Once a token is issued, there is no need to make a database request to verify a users authenticationTo add JWT to .NET Core project use the package : System.IdentityModel.Tokens.Jwt by MicrosoftClass to generate JWT Tokenusing System.IdentityModel.Tokens.Jwt;using System.Security.Claims;using System.Text;using API.Entities;using API.Interfaces;using Microsoft.IdentityModel.Tokens;public class TokenService : ITokenService{ private readonly SymmetricSecurityKey _key; public TokenService(IConfiguration config) { _key = new SymmetricSecurityKey(Encoding.UTF8.GetBytes(config[&quot;TokenKey&quot;])); // PrivateKey } public string CreateToken(AppUser user) { var claims = new List&amp;lt;Claim&amp;gt; { new Claim(JwtRegisteredClaimNames.NameId, user.UserName) }; var creds = new SigningCredentials(_key, SecurityAlgorithms.HmacSha512Signature); var tokenDescriptor = new SecurityTokenDescriptor { Subject = new ClaimsIdentity(claims), Expires = DateTime.Now.AddDays(7), SigningCredentials = creds }; var tokenHandler = new JwtSecurityTokenHandler(); var token = tokenHandler.CreateToken(tokenDescriptor); return tokenHandler.WriteToken(token); }}Authentication middleware in .NET 6To add the authentication middleware, we need to first add the package Microsoft.AspNetCore.Authentication.JwtBearer by MicrosoftThen we need to add the following in the configureservices() method in startup.csservices.AddAuthentication(JwtBearerDefaults.AuthenticationScheme) .AddJwtBearer(options =&amp;gt; { options.TokenValidationParameters = new TokenValidationParameters { ValidateIssuerSigningKey = true, IssuerSigningKey = new SymmetricSecurityKey(Encoding.UTF8.GetBytes(_config[&quot;TokenKey&quot;])), ValidateIssuer = false, ValidateAudience = false }; });After adding this, we need to add the useAuthorization() middleware after useAuthentication() in the configure method.To allow only authorized users to access an endpoint, we use the Authorize attribute on the particular method.Now to access the endpoint, we need to send the JWT token in the authorization header along with the request headers in the format Bearer &amp;lt;jwtToken&amp;gt;." }, { "title": "Building the skeleton of an Angular 12 and .NET 6 Application - Part 2", "url": "/posts/angular-dotnet-app-part2/", "categories": "Blogging, programming", "tags": "development programming dotnet6 angular12", "date": "2022-05-24 10:40:00 +0530", "snippet": "IntroductionIn this blog, we’ll be looking at how to build the structure of an application with .NET 6 as the backend and Angular 12 as the frontend. This is the second part of the blog where we’ll be creating the Angular 12 application. Please read part one of the blog here on how to create the .NET 6 API.VersionsAngular has a major release every 6 months. The current lastest version when writing this blog is Angular 13. However we will be creating our application using Angular 12. To run Angular 12 install nodejs version greater than 16.10.Setup/InstallationTo check the currently installed node version run node --versionTo install Angular version 12 globally run the following command in the terminalnpm install -g @angular/cli@12To check the installed angular version run ng --versionTo create a new Angular application (with strict mode off) run the following commandng new &amp;lt;app-name&amp;gt; --strict false say Y (yes) to Angular routing select css as sytlesheet formatRunning the applicationTo run the Angular application, cd into the directory containing the angular app and run the following command:ng serveThis will start the Angular development server and compile the typescript files into javascript and serve the js files from memory (the complied js files are not physical files, they are stored in memory).Angular File StructureAngular is a single page application. Our single page is index.html file. It has a tag called &amp;lt;app-root&amp;gt; in the body tag. This is an Angular component that will be loaded into our index.html when the app is running. If we inspect the page that is created on running the app, we can see 5 javascript files that were created when we compiled and ran the application. What happens behind the scenes when we run the application is : These js file references get injected into our index.html page by a utility called web pack. Angular does this itself. Web Pack - Webpack is a popular module bundler, a tool for bundling application source code in convenient chunks and for loading that code from a server into a browser. Component&amp;lt;app-root&amp;gt; is our app.component file present in the src-&amp;gt;app-&amp;gt;app.component.ts. This component has a class named AppComponent. It has a decorator @Component. Typescript supports decorators. This is a way of giving a normal class extra powers. Here, it gives a class the ability to be an Angular component. This provides configuration meta data that determines how the component should be processed, instantiated, and used at runtime.Component is the basics UI building block of an Angular application. Components will provide the data for the view inside the browser.Each component has: selector templateUrl styleUrlsAngular components will always create seperate files for the html and css files (to make it more structured). We can pass data from our component.ts to our view component.html. This is done using interpolation ``````import { Component } from &#39;@angular/core&#39;;@Component({ selector: &#39;app-root&#39;, templateUrl: &#39;./app.component.html&#39;, styleUrls: [&#39;./app.component.css&#39;]})export class AppComponent { title = &#39;client&#39;;}How does Angular provide the app.component to the index.html. How is it bootstrapped?The browser doesn’t know what &amp;lt;app-root&amp;gt; tag is and it gets this from the js files. ModuleEvery Angular application should have atleast one module. In a standard angular file, it is app.module.ts file. Inside it we have a decorator @NgModule to tell angular that this is an Angular module. Angular module file has: declarations imports providers bootstrapThe module file declares the components that are available in our application. They will be in the declaration array.We can import other angular modules into the app.module in the imports array.We also have a bootstrap element to bootstrap any components when our application loads. The AppComponent is bootstrapped when the module file app.module.ts is bootstrapped. The AppComponent file is the one we see in the index.html file.import { NgModule } from &#39;@angular/core&#39;;import { BrowserModule } from &#39;@angular/platform-browser&#39;;import { AppRoutingModule } from &#39;./app-routing.module&#39;;import { AppComponent } from &#39;./app.component&#39;;@NgModule({ declarations: [ AppComponent ], imports: [ BrowserModule, AppRoutingModule ], providers: [], bootstrap: [AppComponent]})export class AppModule { } Main.tsHow is the app.module.ts file bootstrapped?The main.ts file has platformbrowserdynamic which is responsible for providing the code to bootstrap our AppModule. Once the AppModule is bootstrapped by the main.ts, it then bootstraps the AppComponent. AppComponent is called in index.html with the selector &amp;lt;app-root&amp;gt;.Typescript gets it’s configuration from tsconfig.json file Angular.jsonIt provides necessary configurations to angular cli. We provide extra scripts, styles to our app in this file. While building the app, the builder looks at this file to find the entry point of the application which is main.ts which bootstraps AppModule.Setting up VSCode for Angular developmentUseful extensions for better angular development on VSCode are: Angular Language Service Angular Snippets Brackets pair colorizerLifecycle Events/Lifecycle HooksAngular has different lifecycle events. A component instance has a lifecycle that starts when an Angular instantiates the component class and renders the component view along with its child views. The lifecycle ends when Angular destroys the component instance and removes its rendered template from the DOM. We can use lifecycle hook methods to tap into key events int he lifecycle of a component. NgOnInit:When we make an http request to an API, it is an asynchronous request. It will take some time to fetch the data and bring it back. So, it cannot be done in the constructor and is done in the NgInit() lifecycle method.Angular handles asynchronous code using Observables. We have to subscribe to the observable to get the data.Making an http request to the APITo make an http request from Angular to the .NET Core API, we have to add the HttpClientModule to the app.modules.ts. Then add this as a dependency injection to the constructor of the app.component.ts class and use the get method to call the api.this.http.get(&#39;https://localhost:5001/api/users&#39;).subscribe(response =&amp;gt; { this.users = response; }, error =&amp;gt; { console.log(error); });While making this request, we are likely to face the CORS(Cross Origin Resource Sharing) error.Resolving CORSCORS is a security mechanism. This is built into all mordern web browsers. It blocks all the http requests from our front-end to any API that is not in the same origin.Here API is running at localhost:5001 and client at localhost:4200, thus different origins. We are not allowed to get resources that exists in a different origin unless the resource says that it’s okay.This can be solved at the API side by adding the following configs in the startup.cs - in configureservices partservices.AddCors();- in configure part after routingapp.UseCors(x =&amp;gt; x.AllowAnyHeader().AllowAnyMethod().WithOrigins(&quot;http://localhost:4200&quot;)); - Adds a CORS middleware to your web application pipeline to allow cross domain requests.When this is done, access-control-allow-origin: http://localhost:4200 is added along with the response headers to the api request and it works.Displaying data in the html pageTo display the users in the html page, we can use the structural directive, loop through the users and list them.NgFor - Structural directive. It modifies the domain object model in our html&amp;lt;ul&amp;gt; &amp;lt;li *ngFor=&quot;let user of users&quot;&amp;gt; - &amp;lt;/li&amp;gt;&amp;lt;/ul&amp;gt;Adding styling frameworks to the Angular application Adding Angular Bootstrap (NgxBootstrap)The following command will install bootstrap, add stylesheets to angular.json file, add module to app.module.tsng add ngx-bootstrap Add font awesomenpm install font-awesomeUsing https in AngularTo allow angular to user https, add an ssl certificate and key to the angular application and make the following changes in the angular.json file&quot;options&quot;: { &quot;sslKey&quot;: &quot;./ssl/server.key&quot;, &quot;sslCert&quot;: &quot;./ssl/server.crt&quot;, &quot;ssl&quot;: true }," }, { "title": "Building the skeleton of an Angular 12 and .NET 6 Application - Part 1", "url": "/posts/angular-dotnet-app-part1/", "categories": "Blogging, programming", "tags": "development programming dotnet6 angular12", "date": "2022-05-20 10:40:00 +0530", "snippet": "IntroductionIn this blog, we’ll be looking at how to build the structure of an application with .NET 6 as the backend and Angular 12 as the frontend. In addition we’ll be using SQL database and use Entity Framework Core as the ORM for data access. Here, we will mainly focus on the .NET 6 / backend part.Setting up the Development EnvironmentWe have to install the following softwares: .NET 6 Node.js Visual Studio Code PostmanThe first step is to download and install .NET 6 latest release. As we are using typescript and Angular in the frontend, we need a javascript engine that allows us to run our javascript application. It is also used to compile our typescript that we use to write the Angular code into javascript. Thus, we also need to insall Node.js.We can use Visual Studio Code as the IDE to code the application. It can be used to write both the Angular and .NET Code.We use Postman for API Testing.Building the Walking SkeletonA walking skeleton is a tiny implementation of the system that performs a small end-to-end function. It need not use the final architecture, but it should link together the main architectural components.The architecture and the functionality can then evolve in parallel.In simple terms, we will have some data in the DB. We will create an API project that fetches the data from the database. We will create an Angular project that can query the API and recieve the data from our API that comes from the DB and display it in the client browser.Creating .NET API ProjectWe will be building the .NET API project using the dotnet cli (command line interface). The first thing to check is if dotnet was installed successfully. This can be done using:dotnet --infoTo get help:dotnet -hTo get contextual helpdotnet new -h (use the name of command which we need help for)To create gitignore filedotnet new gitignoreThe steps to be followed are: Create a solution file - dotnet new sln Create Web API project - dotnet new webapi -o API Add API project into solution - dotnet sln add APISetting up VSCode for C# developmentUseful extensions for better c# development on VSCode are: C# for VSCode by Omnisharp C# Extensions by JosKreativ (for creating class directly with template) Material icon theme by Philipp Kief Nuget Gallery by psiclo SQLite by alexcvzzOther basics setup to be done: Enable Autosave Add assets files (build and debug) - will add a .vscode folder with launch.json, tasks.jsonDifferences in .NET 5 and .NET 6 API projectsIn the .NET 5 project we will have both startup.cs and program.cs files. The .NET6 will have only program.cs file. There are implicit global using statements in .NET 6 and there is also the nullable option. If it is ON, we need to provide a ‘?’ on any of the properties that could be null.The program.cs class has no main method. It is defined implicitly. It just has the code of both the ConfigureServices and Configure methods in the startup.csFamiliarising .NET API ProjectTo make the https certificate of dotnet trused by the browser, use the following commanddotnet dev-certs https --trust To build the project: dotnet build To run the project: dotnet run - This runs the API server at https://localhost:5001/How it works (A bit technical) Program.csEvery .NET application has a program.cs class. Within this class is the Main method. When the dotnet run command is executed, it looks for the main method and executes any of the code inside this method. The main method calls another method inside the program class called CreateHostBuilder. This method Uses Host.CreateDefaultBuilder method which initialises a new instance of HostBuilder with pre-configured defaults. It sets the root-path: where to get files that are part of our project. It loads the configuration. It sets up logging, and returns an IHostbuilder. It also points to use the startup.cs class. Startup.csThe startup class has a constructor, ConfigureServices(), and Configure() methods. Constructor - configuration is injected into the startup class through the constructor [This means the configuration provided in the files like appsettings.json, appsettings.development.json, userSecrets etc] ConfigureServices() - It is often referred to as the Dependency Injection container. If we want to make a class or service available to other areas of our application, we can add them inside this container and .NET core will take care of the creation and destruction of these classes. Configure() - This is used to configure the HTTP pipeline. As we make a request from our browser to our controller endpoint, the request goes through a series of middleware on the way in and the way out. The default middlewares used are: redirection, routing, authorization, and the middleware to use the endpoints and map to controllers. It looks inside the controller to see what endpoints are available and map them accordingly.While adding a service to the ConfigureServices / Dependency injection container, we need to specify it’s lifetime ie, how long this service should be alive for after we start it. There are 3 types of lifetimes supported by ASP.NET Core for the dependency injection, Transient Service - When you ask for an instance, always returns a new instance Scoped Service - Whenever you create an instance, it will be created once per user and shared across all requests by that user. User specific scope.It is scoped to the lifetime of the http request (in case of API request). This is used mostly with API requests. Singleton Service - Only a single instance is created and will be shared across the application for all users.It is created and doesn’t stop until the application stops. LaunchSettings.jsonWhen we run the application using dotnet run, Then it takes a look inside API section in the launchsettings.json to check which url to launch the app.We can also use dotnet watch run to use a filewatcher to examine the filechanges in the terminal.Entity Framework CoreAn Entity is the abstraction of a physical thing. As for basics we’ll create a user Entity.public class AppUser{ public int Id { get; set; } public string UserName { get; set; }}Entity framework is an object relational mapper (ORM). It translates our code into SQL commands that updates tables in the DB.Earlier we used to use ADO.NET to perform database operations which was cumbersome. So Microsoft introduced the entity framework.When using Entity Framwork we need to add an important class which derives from DbContext class that we get with Entity Framework.This class acts as the bridge between our Domain (Entity classes) and the Database. DbContext is the primary class we use to interact with the database.Entity framework allows us to write LINQ (language intergrated queries). EF supports different database providers like SQL Server, SQLite, Oracle, etcThe database provider is responsible for translating the LINQ queries to a SQL Command.DbContext: - Suppose we have a class called DataContext which inherits DbContext, then it should have a constructor which takes in DbContextOptions.The options to the constructor will be passed when we add the DataContext as a service in the startup.cs DI configureservices.We will pass in the connection string as one of the option of datacontext.We will define the connection string inside the appsettings.developement.json file. This config is then passed into the startup class and then to datacontext.This class will also contain the DbSet&amp;lt;Entity&amp;gt; Name {get; set; } where Name defines the table name in sql.Features: Allows to query database using LINQ. Allows to keep track of changes in our entities. Allows to save - insert, update, delete to db using savechanges method. Uses concurrency to protect overwriting changes made by another user since data was fetched from DB. Deals with transactions. First level caching out of box. (repeated querying returns data from cache insted of hitting the db) Offers built in conventions Offers migrationsWe are abstracted away from the database. So code/entity isn’t affected by the DB.It has Code-First and Data-First approaches to create database/code. The commonly used method is code-first approach.To make use of Entity framework, we need to install Microsoft.EntityFrameworkCore.Sqlite (version matching dotnet runtime version) Microsoft.EntityFrameworkCore.DesignTo manage the db ie, create database and tables via EF, we need to install a tool called dotnet-efdotnet tool install --global dotnet-ef --version 6.0.0 Adding migrationCreating a migration based on the code we have written (the entities and datacontext)This will create a database schema / code to create our database.dotnet ef migrations add InitialCreate -o Data/MigrationsThe migration will add Up and Down methods. Updating databaseAfter adding the migrations. We can create/update the database by adding/removing the tables.dotnet ef database update Droping databaseIncase you want to delete the database.dotnet ef database dropCreating API Controllers An API Controller will have an attribute called [APIController]. This signifies that this class is of type apicontroller. We also need [Route] attribute for this controller. how the user reaches the api controller from the client eg:- [Route(“api/[controller]”)] A controller needs to derive from a ControllerBase.We can Get, Post, Put, Delete using controllers by using [HttpGet], [HttpPost] attributes etc.API Calls should be asynchronous. By doing this we can make the application more scalable." }, { "title": "Basics of Stock Market", "url": "/posts/stock-market/", "categories": "Blogging, Stock Market, Personal Finance", "tags": "stocks investing financial wealth", "date": "2022-05-19 19:40:00 +0530", "snippet": "IntroductionIn this blog, we will go through the basics of stock market trading/investing.Why Stock Trading?Two of the main reasons to be involved in stock trading are: Trade/Invest your money to generate income. Trade other people’s money to generate income.So the basic purpose is to generate capital. Everyone has to learn about the stock market at one point or the other in their lives.What is a Stock?A Stock is a security that signifies ownership in a corporation. By having stocks in a company you have claim on their assets and earnings. By owning stocks/shares in a company you become a part owner of the firm. A company sells/issues its stocks when it needs to grow by raising a capital. The investor who buys the stock can participate in the growth of the company by owning a part of it (He doesn’t even need to put in work). Traders look for mispricing of stock and if they are able to evaluate when the price is too high or too low, they can take advantage of it and make profit.Buying a stock:It depends on whether the stock is private/public. Private company:A private company is one with relatively small amount of owners and doesn’t trade on public exchanges.It is relatively not easy to invest in private companies. We need to be either acquainted with the owner or be a qualified investor with a lot of money. Thus it’s difficult for private companies to get funded. Public company:A public company is a big company that trades on the public exchange. eg:- Apple, Meta, NetflixAnybody can invest in public companies. You can buy it’s stocks using the brokers from the public exchange where it is traded.What is a Market?A market is a location where people go to buy and sell products. Markets are characterised by the products that they specialize in. The Stock market works like an auction market. In an auction market, buyers bid on the best price that they are willing to pay for a product and sellers bid on the price on which they are willing to sell the product. There are two types of stock markets Primary Market: The market that the stock trades in the first time. Secondary Market: Every other time that the stock trades after the first time.The stock becomes second hand. ie, somebody else owned it before you. In order for a company to go public, it needs to go through an IPO (Initial Public Offering) IPO (Initial Public Offering) Selling stocks from your company to the public for the first time ever. The public will pay for the part of the company you sale to them.An underwriting firm will analyse our company and figure out the best price at which our stock can be sold at the beginning. They help us get the required amount of money byselling the decided amount of stocks. The first selling of these stocks/shares will happen in the primary market. It is very hard to get shares from the primary market (ie, through IPO). When we talk about the buying and selling of stocks/securities we will talk about the secondary market.What is a Stock Exchange?Exhanges refer to the exact location where the trades are being executed. eg: Let’s take the case of grocery stores. The term can be compared to that of a Market. But if we refer to a specific store, like Walmart, these can be compared toan exchange.In the Stock Market, we have different exchanges that we can goto to buy and sell stocks. eg: NYSE (NewYork Stock Exchange), NasdaqBack in the 1700’s or 1800’s, to buy a stock, we had to find a person who wanted to sell our required quantity of a stock at the price which we are willing to buy it. It was a very difficult process. So, there were regular meetups in the townhalls and in city centers where people meet and trade stocks. One of those was in New York where financially savy people met and sold/bought stocks. A group of people who started this saw that it was a hassle dealing with lots of people to meet up like this so, they decided to sign an agreement with one another called the buttonwood agreement. The agreement said that they weren’t going to trade stocks with anyone else but themselves (they were 24 people). If someone wanted to buy/sell stocks from them, they were going to charge a commission (a percentage). This location was called the New York Stock Exhange (It originally consisted of 24 brokers). The three main exchanges in the United States are : NYSE - Biggest and most demanding exchange (They look at the company before listing in this exchange) Nasdaq - Less demanding and most tech companies are on this exchange Amex - It is an exchange that caters to ETF’s (Exchange Traded Funds)Some companies are listed in more than one exchange, But mostly they are only listed in one exchangeWhat is a Broker?A broker is somebody who you’re going to have to go through to buy/sell a stock. When you want to buy a stock, you have to go to the broker and let him know what stock you want to buy. He will see if another brokers client wants to sell the stock that you want to buy and see if your prices match so that you can transact with one another. As the brokers became more busy, they hired floor brokers. Earlier everything was done manually where the floor brokers would meet physically but with time, it became automated where we can execute orders using a computer and thus didn’t require floor brokers. However, we still have to go through the broker to request that we want to buy/sell the stock only the match-making process at the exchange is automated. We have to pay a commission to the broker for them to route the order to the exchange and do the necessary paper work.Orders and Order TypesHere, we will discuss what we have to do when we want to buy/sell a stock. We already know we have to contact a broker for this but what should we tell him. We have to send the broker an order of what you want. The things that need to be specified in an order are: Ticker - An abbreviation for the name of the company eg: Microsoft(MSFT) Side - Buy/Sell order Type - Market order, Limit order. Market order tells a broker that you want to buy/sell the stock immediately no matter the price. Limit order tells a broker you want to buy/sell the stock at a limit price or better. Market order is time sensitive while limit order is price sensitive. In case of a limit order, we need to provide a price to your order. Quantity - No. of shares to buy/sellOrder Driving PricesMost people think that it’s news or events that make prices move, but the actual thing that drives prices is orders that people send. Shares outstanding refers to the amount of shares that your company has.Floats: The amount of shares that are currently trading in the market. Level 2/Book: Represents every single buyer and seller that’s out on the market. From the book or level 2 we create level 1. In level 2, the orders on the buy side are placed according to a price priority and then time priority. The order with the highest price is placed on top of the buy side and the one with lowest price is placed at the top of the sell side. If two orders have the same price, then the one which came first will be on top. Level 2 updates everytime a new order is placed. The order at the top of level 2 buy part is the best ask and the one at the top of it’s sell part is the best bid. Electronic list of buy and sell orders for a stock. This list is ordered by price and then by time. The order book lists the number of shares on the bid and ask at every price point. Level 1: It is the best price/bid/offer available on the market. It is updated everytime the best ask/best bid in the level 2 gets updated. Level 1 is an abbreviation for level 2 and Time and Sales. It contains the best ask/bid from level 2 and the last price from Time and Sales. It will give us a general idea of the market. Displays the bid and ask prices as well as quantities. This also displays the last trade executed. Time and Sales: This is where the exchange records everything. The exchange has to report on every execution that happens. On it they have to put the name of the stock that they are trading, the time that the trade happened at, the quantity and the price that it happened at. This comes out at the time of sales. The last price at which the stock was executed at is the LTP and will be shown while checking for the price of the stock. Displays every single execution that happens on the market. The executions are displayed real-time and include information like: time, direction, quantity traded and exchange traded on.Supply and demand is shown through the order book that you can access at level 2, see all the buyers and all the sellers and the price will fluctuate based solely on the orders that people send. The price movement comes from the order matching with one another on the execution system/the matching system at the stock exchange. Bid: The best price you can buy on. Ask: The best price you can sell on. Spread: Difference between ask and bid. The difference between the price of best person who wants to buy and the person who wants to sell. If a stock has an ask of 52 and a bid of 50 and we want to buy it, we can buy it at 52$ and if we sell it next we will sell it at 50$. Thus loosing 2$ in the process even though the stock hasn’t moved. The 2$ is spread. While trading we have to watch out for the spread of a stock. NBBO (National Best Bid and Offer): This represents the highest bid and lowest ask available on the market.Different PlayersDifferent players in the market trade differently. A mutual fund or somebody who has a lot of shares is not going to trade like somebody who is just sitting at home and trading ie, a retail trader. A mutual fund will sell when there’s a good news since then, a lot of buyers will be there. We have to know the institutional ownership of a stock. We need to know who we are trading against. At the end of the day, day-trade is a zero sum game meaning every dollar that we take into our pocket comes from somebody elses pocket. So, we need to know the person we’re taking money from. Prices are going to move because of the buy orders and sell orders that people/participants are sending so we have to know who those participants are. Because they send orders in a different type of manner.The different players are: Proprietary Trading Firms (Have lots of tools, information, access and strategies) Investors (They invest for a long term) Retail Traders (Traders trading from home without sophisticated tools, information or strategies) Portfolio Managers (Mutual fund managers - Take money from lot of investors and trade using it) Hedge Funds - Like mutual funds, they have big capital and not anyone can put money in a hedge fund. You have to be someone who’s rich enough as they have a minimun investment amount. They are more sophisticated than mutual funds and outperform them. They are very discrete (We can’t know what they are doing.)3 ways of making money in Stock Market Going Long - Buying a stock and selling it at a higher valuation to make money. Going Short - Betting that a stock is gonna go down. We make money when stock drops in value. We can short stocks in a margin account. Here we borrow stocks from a broker, then sell it and after it goes down buy it back, take the difference as profit and give back the stock to the broker. Being Flat - Being flat means having no positions. If you’re busy then don’t trade, this is a good position to be in.Introduction to Technical AnalysisWe have two ways to try and predict where stock prices are going to go. These two are: Fundamental Analysis (Evaluating the stock fundamentally - how many employees, tax system, environment, revenue, expenses, debt) - Used for long term investing Technical Analysis (We only check Price and Volume of shares being traded) - Used for trading (Day trading, swing trading)Charts &amp;amp; CandlesticksChart - Charts are just a graphical representations of past price action. Chart is the prices that a product traded at each point in time. When looking at a chart, we are observing historical prices of a stock. Prices going up indicates that the demand for the stock was higher than it’s supply. If prices are going down, it mean more people wanted to sell that product and less people wanted to buy it. Traders use charts to predict where the stock go in the future based on how it moved in the past. Line ChartsIt connects every price point throughout time with a line. Line charts aren’t sufficient enough to get a full picture of what actually happend. That’s why almost always we use candlestick charts. Candlestock ChartsCandlestick is something we draw for each day. A candlestick shows opening price, close price, high price, and low price during a day. In the US and Canadian markets, the market opens at 9:30am, the first trade that happens when the market opens is the opening price. If the first trade happens at 10$, it is the opening price. If the stock price then goes down to 9$, then goes up to 13$ and closes at 12$. Close is the last trade that happend during the day. ie, at 4pm when the market closes. The highest price that the stock traded during the day here 13$ is the high price and the lowest price that the stock traded in during the day 9$ is the low price. By connecting these prices we form a candle. By looking at this candle, it’s top shows the high price, bottom show low price. If a candle is drawn in green, it means it’s price went up today. It opened at 10$ went down to 9$ but closed at 12$. So in effect it went up by 2$ or 20%. Another example is a stock opened at 10$, went up to 12$, then went down to 6$ and closed at 8$. So here the candlestick will be red color and the price went down by 2$ or 20%.All candles are composed of an upper shadow, lower shadow, open, close, high, and low.If the open is higher than the close we have a red.If the close is higher than the open we have a green.CandleSticksA graphical representation of the high, low, opening and closing price of a security for a specific period. A green Real Body represents a stock that closed at a higher price than it opened at. A red Real Body represents a stock that closed at a price lower than it opened at. A candlestick can be for any period of time. It can be for a day, a week, for 5 minutes etc. We can have candles for any timeframes. Different candles mean different things.The different candlesticks are: Big CandlesAs the name suggests, a big candle is a candle of a large size. It indicates that the prices either went down a lot or went up a lot. A bigger candle means a bigger imbalance between how many buyers there were and how many sellers. Dojis CandlesDoji means indecision. Dojis form when the opening and closing prices are virtually equal. Alone, dojis are neutral patterns. It opens at a price say 10$, then goes up to 14$, then goes down to 8$ they goes up to 10$. It’s opening and closing prices are the same ie, 10$. This indicates indecision of where the stock should go. Neither buyer nor seller wins here. Long Legger Doji CandlesA Doji with a bigger wick (Wick referes to the high and low on a candle). It means buyers were winning by a bigger amount at one point but then sellers were winning by a bigger amount. But at the end of the day/period, the closing price of the stock is the same as the opening. Which means there is big indecision about where the stock is going. GraveStone CandlesHere the stock goes all the way up to a certain point meaning there are a lot of buyers (Strong demand) but then it stops and sellers start selling and the price drops all the way to where it opened at. The long upper shadow suggests that the direction of the trend may be nearing a major turning point. It is formed when the opening and closing price of the underlying asset are equal and occur at the low of the day. DragonFly CandlesHere the stock opens at a price, drops then comes back to the opening price and closes there. The long lower shadow suggests that the direction of the trend may be nearing a major turning point. It is formed when the opening and closing price of the underlying asset are equal and occur at the high of the day. Morning Doji StarMorning Doji Star Consists of a large red body candlestick followed by a Doji that occurred below the preceding candlestick. On the following day, a third green body candlestick is formed that closed well into the red body candlestick which appeared before the Doji. It is considered as a major reversal signal. Indicates a bullish trend.Stock goes down with red candlestick until it reaches a doji indicating an indecision, then next candle is a green one. This forms a reverse signal indicating that it may go up subsequently. Dojis make sense when put within a pattern. We can us the morning doji star pattern to time the buying of a stock. If it forms the morning star pattern, we know it will go up eventually so we can time it here and buy it. Evening Doji StarEvening Doji Star Consists of three candlesticks. First is a large green body candlestick followed by a Doji that gap above the green body. The third candlestick is a red body that closes well into the green body. When it appears at the top it is considered as a reversal signal. It signals a bearish trend. Shooting StarHere the stock opens at a certain price, goes all the way up and come down and closes just above where it opened. It will have a small green candle. A black or a white candlestick that has a small body, a long upper shadow and a little or no lower tail. Considered a bearish pattern in an uptrend. HammerHere the stock opens at a certian price, goes all the way down and come up and closes just below where it opened. It will have a small red candle. A black or a white candlestick that consists of a small body near the high with a little or no upper shadow and a long lower tail. Considered a bullish pattern during a downtrend. Bearish HaramiHere we have a very big green candle and then a smaller red candle that opens within the body(within open and close of the candle) of the green candle. In a chart this indicates that the up movement has exhaused. So, we expect a trend reveral ie, the stock to go down. As the name bearish suggests we have a view that the stock will go down. Bullish HaramiHere we have a very big red candle and then a smaller green candle that opens within the body(within open and close of the candle) of the red candle. In a chart this indicates that the down movement has exhaused (Sellers have exhausted). So, the stock will go up. As the name bullish suggests we have a view that the stock will go up. Bearish and Bullish Harami helps to time the buy/sell of stocks. Engulfing BullishHere a green candle engulfs a smaller red candle indicating the stock will go up. Consists of a small red body that is contained within the followed large green candlestick. When it appears at bottom it is interpreted as a major reversal signal. Engulfing BearishHere a red candle engulfs a smaller green candle indicating the stock will go down. Consists of a small green body that is contained within the followed large red candlestick. When it appears at top it is considered as a major reversal signal.TrendsTrends is something that is at the core of technical analysis. Prices tend to move in trends and history tends to repeat itself.A trend is just a direction. Stocks can have trends they can go in one direction. They can have an uptrend meaning it is going up. They can have a downtrend meaning it is going down. Stocks only move in three directions - up, down, and side. UpTrendsStocks don’t move in a straight line, they will fluctuate. In an uptrend, every time we have a high, the next high is higher and every time we have a low, the next low is higher. DownTrendsIn a downtrend, every time they have a high, the next high is lower and every time we have a low, the next low is lower. SideTrendsIf the lows and highs are at the same price, the stock is moving sideways.If a stock a going up in an uptrend, then it will probably be going in that direction. That’s why it’s said go with the trend/ the trend is your friend. Don’t go against the trend. TrendLines: A line we draw along the lows of a trend. It will give us the general direction of the trend weather it’s up/down. Trends don’t last forever. If the price of a stock breaks the trendline that we drew, then it’s over it won’t continue in the same direction as the trend. Channels: When drawing trendlines we draw 2 lines one on the high and one on the low of the trend and we call it a channel. The stock will move in a channel within a lower and upper trendline. We can have up channels where the stock is going up and down channels where the stock is going down. We also have side channels. Within a channel, we can buy when it’s at a lower and sell when it’s in the upper. Drawing channels on stock charts will help us to time the buy and sell of a stock. Support and ResistanceChannels and trendlines serve as support and resistance. Support is something that supports a price, supporting that it doesn’t fall below a certain price. Resistance is something that the price can’t go through (It can’t go higher than this). The lower trendline is a support line. The upper trendline in the resistance line. When we are trading a stock in the support and resistance, we should buy on the support and sell on the resistance. Trends can be observed in any timeframe, daily, 5 minutes etc. Trends can channels will help us to decide on the entry and exit points. It has been proven that trends persist. The real reason why is because almost everyone sees the trend line and wants to buy on the support line so, place buy orders on the support line which inturn create high demand for the stock at that point and ensures it doesn’t go below it. Support and resistance are caused by people buying and selling on the high and low trend lines.Support and resistance values will often be round numbers since people will buy at values like 100,50,75,25 etc. We should buy above support and sell below resistance points. Since support and resistance will be in round number values, buy and sell in non-round values like 75.04, 99.9 etc because there will be many people placing order at 100, 75 etc and it will be very difficult to buy at that value. A stock going in an uptrend and suddenly breaks it’s support and goes down. When it breaks support, the support/resistance role is reversed. The previous support line now becomes the resistance line. If it was in a downtrend, and it breaks the resistance, it will become the support.Support and resistance are stronger in intra-day trading because it’s the same people who are buying and selling. Stock Screener for traders: FinvizPrices of stock are only affected by what other people are going to be doing. Trend LengthsThere are trends with different lengths like long-term trend, medium-term trend, and short-term trend. Within a long-term downtrend, there can be multiple short-term uptrends and medium-term uptrends. We should analyse the trend depending on how long we are planning on holding the stock. If we are doing intra-day, then short and medium trends are useful.Chart PatternsThey give you an indication of either continuation or reversal. Observing chart patterns will help us to identify if the stocks will keep on going in the same direction or will go in the opposite direction. This happens because history tends to repeat itself in technical analysis. Since it’s people who are responsible for up and down of a stock, it is in correlation with their emotions. Emotions of people don’t change over time so, what happened earlier tends to repeat itself. Some of the main chart patterns are: Head and ShouldersIt’s one of the most famous chart pattern. It is called so because in this pattern the stock goes up to a high then goes down, then goes up again to a point higher than the previous high. Then it goes down and goes up to a point lower than previous high. There is left shoulder, head, right shoulder. In this case the support is called neckline.The theory behind head and shoulders is that after the second shoulder, since it wasn’t able to go as high as the previous high, it’s going to break the neckline and if it does break the neckline, it gives us an indication to sell the stock. We would expect the stock to break. Double TopIt is a chart that topped at 2 different locations. It went to a high then traded somewhere else (went down), then came back to that high but wasn’t able to break it and came back down. Now we have 2 tops. What this chart tells us is that the 2 tops price level is a resistance for the stock ie, stock fails to break that point. The stock is unable to break this top because there is probably a seller trying to sell the stock by a limit at that top to make profit. Double tops are useful in various time frames. Multiple TopIt is very similar to double top but has multiple tops. The difference is that it tested that top another time and failed to break it making it more stronger. Double BottomIt is the opposite of double top. Here the stock goes down to a certain point then goes back up and then goes down but not beyond the previous down point. It has a support line and most likely won’t break it. A lot of people will be placing their buy orders at that point. Multiple BottomSame thing as Multiple top but it has multiple points in the bottom. It will have a strong support line. Triangles Ascending Triangle : Here the support line will be going up. Buyers become more aggressive and are willing to pay more for the stock thereby making each subsequent down point higher than the previous one making a support line that is point up. The resistance line is straight. It will reach a point where the buyers and sellers reach same price point. Who wins at that point decides where the price will go from there. The buyers have a more chance of winning and the stock prices will go up. Descending Triangle: It’s the same thing as the ascending triangle, but here the sellers become more aggressive and start selling at lower price. Here the sellers will push it down and the stock prices will go down. We should take position after the break happens ie, when the sellers and buyers price meet. This decides whether the price will go up or down. Regular Triangle (Wedge): Here sellers are selling at lower and lower prices and buyers are buying at higher and higher prices. Both the sellers and buyers are being more and more impatient. This forms a wedge or a triangle like shape. In the end either the seller or buyer will win and it will break out in one direction. Once it breaks, it will continue to go in that direction. Once it breaks and goes up, the previous resistance becomes support. If the price goes further into the wedge, it will really explode when it breaks out. In case of wedges we can have wedge up, wedge down. Cup and HandleIt is a very rare chart pattern. Here the price starts dropping, but then it starts dropping slower and slower and then it stops and then it starts picking up and it picks up very faster and after that it reconsiliates and breaks up and goes up as much as the distance it went down. Here the prices dropping and rising forms a cup and while reconsiliating forms a handle thus, called so. Rounding BottomIt looks somewhat similar to cup and handle, but doesn’t likely have a reconsiliation. Once it picks up, it likely goes up higher. Only the patterns used by most people will affect the behaviour of a stock price. VolumeTechnical analysis mainly deals with price and volume. If a 100 shares traded hands then the volume of the stock is 100. Volume describes the number of shares that were sold and bought. On each day we can see how many shares of a particular stock were traded. Volume is important as we need enough quantity to be traded at a price to confirm the price it’s trading at is valid/correct. A price movement without enough volume is meaningless. Volume preceeds price. When something happens and the stock is going to move, a lot of volume will come in before the price begins to move. Before prices start to go up, a lot of people will be buying the shares meaning an increase in volume, only then the prices will start moving up as there is an increase in demand. If the prices are going up but there is very less volume, then the probability of continuation is very low.Big moves in stock price are supported with high volume. It could either be prices going down or up. If there is a movement with less volume it could mean that there weren’t many sellers to sell at a meaningful price and thus the buyer had to purchase at a higher price, thus the price wouldn’t continue to go up. Average VolumeAverage amount of shares that a company buys/sells. We usually look at the 3 month average of a stock. We look at the average since in some days it can trade at a low volume and in some days high volume. The average daily quantity of shares that have been traded for the past X period. Usualy this is calculated on the past 3 months. Relative VolumeRelative volume compares the current volume to the average volume that the stock should have at the same time of day. If the relative volume is over 1 this means the stock is experiencing more then it’s usual volume. If for example the relative volume is 4, this means the stock is experiencing 4 times it’s usual volume. To understand if the volume of a stock is high/low, we observe the relative volume of that particular stock on that day with respect to how much volume it usually trades. We cannot compare volume of one stock to that of another stock.Indicators: Bollinger BandsTechnical indicator: Mathematical computation based on historical price and volume which aims to help forcast future price mouvement and is mostly used for entry/exit signals.Bollinger bands are one of the multiple indicators that we have access to when we trade stocks. We use bollinger bands when we are running a mean reverting strategy." }, { "title": "Smallcase Investing Explained!", "url": "/posts/small-case/", "categories": "Blogging, Stock Market, Personal Finance", "tags": "stocks smallcase investing financial wealth", "date": "2022-05-14 15:40:00 +0530", "snippet": "IntroductionBefore getting into smallcase we need to understand the difference between Equity Investing and Portfolio/Basket Investing.Equity InvestingEquity investing involves buying the stock of a company directly. eg: ITC . However, this needs a lot of market research (which stock to buy, at what price to buy, when to buy etc) We might loose a lot of money here due to lack of knowledge. Direct equity investing is research oriented.Portfolio/Basket InvestingBuying a basket of stocks. eg:- contains 2,3 stocks. Here, we buy part/the entire basket. Mutual Funds - There are a wide variety of mutual funds. They are a collection of stocks. A mutual fund has an NAV (Net Asset Value). We can buy a part of this basket called a Unit. This is called Unit investing. They are segregated into large cap, mid cap, and small cap. Also into debts (bonds) vs equity(stocks) mutual funds. Smallcase - Smallcase is also a portfolio of stocks. But here we are owning stocks. We don’t do unit investing here.BasicsSmallcases are a portfolio/basket of stocks wherein we are owning the stocks directly in our demat account. There are a variety of themes of smallcases, thus we can do thematic investing. Here, we don’t have to do the heavy lifting as in the case of Equity investing where we have to do a lot of research and spend a lot of time analysing the market.Mutual Funds vs SmallcaseThe similarity is that both are managed by professionals. Mutual Funds: There is very little transpareny in mutual funds. It is very difficult to track where your money goes into. The mutual fund manager decides on which stock to buy/sell and when to do it. There is a certain lockin period for majority of MF’s Divided gets invested. Active MF’s - 1-2% commissions, Entry and exit loads Smallcase: It has very good transpareny. We can easily track how money gets allocated into different indexes/stocks. There is quarterly rebalancing of the portfolio There is no lockin period. We will get the divident directly to our account They are designed by certain fund managers and they can decide the commissions 0-3% Some of them are free but there are transaction cost of 100Rs + Other charges (security, transaction etc) eg:- Windmill capital (In house research team at smallcase) How to invest using Smallcase?Firstly we need a Demat account (Zeroda, Upstox, Groww etc).Then, link this to smallcase.Goto discover tab, search for your basket of interest and invest money in it.Charges involved in Smallcase Investment Charges:Irrespective of the smallcase type, If you’re investing less than ₹4,000 on the buy day, you are charged only 2.5% of the amount invested + GST (18% on fees) and if you are investing an amount greater than or equal to ₹4000 it is 100 + GST (18% on fees). Charges while selling:Selling a smallcase is similar to selling the stocks in it. There are no particular charges while selling a Smallcase - only the STCG/LTCG taxes.Since smallcases are nothing but baskets of stocks bought &amp;amp; managed together, The taxation guidelines that apply for stocks apply for smallcases as you’re eventually holding them in single stocks format. Short Term Capital Gains (STCG) - Stocks sold less than 12 months of holding period would be taxed at 15% of the gains. Not applicable on losses. Long Term Capital Gains (LTCG) - Stocks sold more than 12 months of holding period with a gain of over Rs.1,00,000 would be taxed at 10% of the gains. If the gain amount is less than Rs.1 Lakh, then no amount is taxed.If we get dividents, then the taxes on divided are applicable here as well. Rebalancing Charges:Smallcase will not charge you for rebalancing. But in realterms, it is selling of certain stocks from the portfolio and buying certain other stocks. So there will be some charges like brokerage charges (by the stock broker)." }, { "title": "Mutual Funds", "url": "/posts/mutual-fund/", "categories": "Blogging, Stock Market, Personal Finance", "tags": "stocks mutual funds investing financial wealth", "date": "2022-03-24 19:40:00 +0530", "snippet": "IntroductionMutual funds are a collection of stocks that are managed by mutual fund managers. The mutual fund manager buys and sells stock out of the portfolio of stocks that he/she has created. In comparison to direct equity investment where we directly go to stock market and purchase the stock of a company, here it is done by the mutual fund managers.We can directly invest in mutual funds or through mutual fund agents. We can do SIP (Systematic Investment Plan) or Lump sum (Large amount of money) in mutual funds.Basics of Mutual FundThis is an example of a mutual fund. As the name of the Mutual fund indicates Canara Rob Bluechip Equity Fund is an Equity fund meaning it is a Stock based MF. There are also bond based/debt mutual funds. It also has Bluechip meaning it invests in bluechip companies.At the time of writing this blog, the NAV (Net Asset Value) of this MF is 44.550. This MF will consist of a bunch of stocks in different sectors. We can also view the different companies that it’s investing in.NAV - Indicates the weightprice of all the stocks in the MF divided by total number of companies. It represents the weighted average of the portfolio. It represents the average price of the entire portfolio ie, How much we need to pay for one *unit of this mutual fund. This is analogous to Stock price in direct equity investment.Mutual Funds can be of 2 types: Actively Traded MF: These are the MF’s that are being actively managed by the mutual fund managers. It is traded actively. Pros/Cons: Higher commissions May have Entry or Exit loads. On an average these MF’s have less than 10% returns over a 20 year period. Passively Traded MF: These are NIFTY50/SENSEX funds. Here the Mutual fund manager mirrors the market. If the NIFTY weight has gone up due to the increase in value of one company eg: TCS, then the manager will buy more stock of this particular company. If Reliance weight has gone down, he will adjust the portfolio accordingly.Pros/Cons: Lower commissions (Less research is needed) On an average these MF’s have 12.1% - 12.4% returns over a 20 year period. How to pick a Mutual Fund?Points to consider while choosing a Mutual Fund: Past returns may not necessarily correlate with future returns. We analyse the Mutual fund using the different Investment checklists: Returns: How much returns it is generating. Expense Ratio: Commissions that we are paying out. Return vs FD Rates: Funds generate better price returns than bank FD’s. Red Flags: Check for any red flags (Total holdings with red flags is insignificant) Equity vs Debt AllocationEquity Mutual Funds invest in Stocks. This is riskier in comparison to Debt Mutual Funds. If a company goes bankrupt, the equity investors are paid last when it’s assests are liquidated. - Risk is higher - Higher returns - In early parts of our life we should invest as much as possible in Equity MF’s 70% Equity, 30% Debteg: Canara Rob Bluechip Equity FundDebt Mutual Funds invests in a fund which gives out loans. It is less riskier as the debt fund investors are paid first when the assests are liquidated. - Risk is lower - Lower returns - Invest more during later parts of life.eg: HSBC Debt FundWhich Mutual Fund, How to invest?Here, we can discuss if we should invest in SIP’s or lump sum, ff we should choose passive/active MF’s and if we should invest in equity/debt MF’sAn average investor should invest in: - Large cap Equity mutual funds that invest in bluechip compaines. OR - Passive Mutual Funds like NIFTY50. - Go with companies that has high AUM (Asset Under Management) - Invest in Sectoral Mutual Funds if we have large capital. - Invest money in mutual funds using SIP’s (Systematic Investment Plan) - Invest a fixed amount every month. We will get benifits of the averaging. - Don’t do your SIP’s on 1st of each month. Do it on some odd date (any random day of a month). Try doing it on 22nd, 23rd of the month as everyone invests on the 1st of a month and this can cause less returns according to historic data.The reason why people invest in Mutual Funds is for Dollar Cost Averaging. Each month we invest a fixed amount.When to sell Mutual Funds? If your mutual fund is performing badly, you must sell it. It indicates that the MF has a bad manager. We can do this by comparing it with the NIFTY returns. If we have achieved our goal, we can sell it. Follow a Systematic Withdrawal Plan (SWP). Withdraw money in a timely manner. Withdraw a decided amount every month. It will give you averaging benifit.Some terms to remember: Debt/Equity Mutual Funds Active/Passive Mutual Funds SIP’s/Lump sum" }, { "title": "JavaScript in the DOM", "url": "/posts/javascript-in-the-dom/", "categories": "Blogging, programming", "tags": "development programming javascript DOM", "date": "2022-03-15 16:40:00 +0530", "snippet": "IntroductionThere are three things associated with working with JavaScript Window Document DOM1. Window: It is the global scope.let a = 1; is actually window.a a attaches itself to the global scope that is the window.2. Document: All the things rendered on our page. Everything is rendered inside the documentwindow.document - this is everything on our actual page3. DOM: Document Object Model - This is a model which holds all the object in our page/document. We can manupulate the dom to change the user experience.DOMThere are different ways of selecting objects in the dom: Get element by Iddocument.getElementById(&#39;id-name&#39;); QuerySelectorquerySelector will select the first element which uses the class name/ id/ name of tag. It will give back the first element.document.querySelector(&#39;.class-name&#39;); - select using classdocument.querySelector(&#39;h1&#39;); - select using html tag namedocument.querySelector(&#39;#id-name&#39;); - select using iddocument.querySelector(&#39;div ul li&#39;); - select the li inside the ul in the div. (We can dial into the exact element we are looking for) QuerySelectorAllquerySelectorAll will select all the elements from the page. We can use it to select and manipulate all the elements with similar class/ id/ tag name.let q = document.querySelectorAll(&#39;p&#39;);q.forEach(el =&amp;gt; console.log(el));DOM Samples Change text of an elementconst p = document.getElementById(&#39;first-paragraph&#39;);p.innerText = &#39;This is a test&#39;; Add html to an elementconst list = document.querySelector(&#39;ul&#39;);list.innerHTML = &#39;&amp;lt;li&amp;gt;Test1&amp;lt;/li&amp;gt;&amp;lt;li&amp;gt;Test2&amp;lt;/li&amp;gt;&#39; Remove an elementconst p2 = document.querySelector(&#39;.support-paragraph&#39;);p2.remove(); Change style of an elementconst headingItem = document.querySelector(&#39;h1&#39;);headingItem.style.color = &#39;red&#39;;headingItem.style.fontSize = &#39;1.25rem&#39;; Adding a class to an elementconst p1 = document.querySelector(&#39;p&#39;);p1.classList.add(&#39;dark-mode&#39;); Removing/Adding a class from each of the element in the pageconst paragraphs = document.querySelectorAll(&#39;p&#39;);paragraphs.forEach(el =&amp;gt; { el.classList.remove(&#39;support-paragraph&#39;) el.classList.add(&#39;dark-mode&#39;)});Traversing the DOMWe generally use getElementById and querySelector to find specific element in the page. They look through the entire body of our page to find the element that we want. Once we find the element we want, if we are looking for an element inside it, in the same level or outside it, we traverse that node we have already found and search inside it.We can traverse up/out, down/in, and in the same level from the element that we have currently selected.This is much more efficient to traverse the DOM. Traversing up/outside We can traverse upper using ‘parentElement’ or closest(‘tag-name’) Traversing down/inside We can traverse inside using children or querySelector(‘tag-name’) Traversing same level We can traverse the same level using either ‘nextElementSibling’ or ‘previousElementSibling’``` Our First LI Our Second LI Our Third LI const section = document.getElementById(‘list-section’);const list = section.querySelector(‘ul’);const items = list.children;const itemsArray = Array.from(items);itemsArray.forEach(el =&amp;gt; console.log(el));const section = document.getElementById(‘key-items’);const element = section.parentElement;const mainElement = section.closest(‘main’)console.log(mainElement);const listItem = document.querySelector(‘li’);const nextItem = listItem.nextElementSibling;const finalItem = nextItem.nextElementSibling;const unknownItem = finalItem.nextElementSibling;console.log(unknownItem);while (listItem !== null){ console.log(listItem); listItem = listItem.nextElementSibling;}### Creating HTML ElementsWe can add elements to the page in many different ways.- First Method: This method is a bit slower in performanceconst list = document.getElementById(‘key-items’);list.innerHTML += ‘&amp;lt;li&amp;gt;Our Fourth LI&amp;lt;/li&amp;gt;’const foods = [‘Hamburgers’, ‘Hot Dogs’, ‘Pasta’, ‘Bread’];const foodList = document.getElementById(‘good-foods’);foods.forEach(food =&amp;gt; { foodList.innerHTML += &amp;lt;li&amp;gt;${food}&amp;lt;/li&amp;gt;;});- Second Method: This is better compared to the first one.const foods = [‘Hamburgers’, ‘Hot Dogs’, ‘Pasta’, ‘Bread’];const foodList = document.getElementById(‘good-foods’);foods.forEach(food =&amp;gt; { const li = document.createElement(‘li’); li.innerHTML = food; foodList.appendChild(li);});- Third Method: This one is the most efficient way. Here we create a document fragment and do all manipulations to the fragment and then add it to the page. Here we modify the page only once, when the fragment is added.const fragment = new DocumentFragment();foods.forEach(food =&amp;gt; { const el = document.createElement(‘li’); el.innerHTML = food; fragment.appendChild(el);});foodList.appendChild(fragment);### EventsHTML events are &quot;things&quot; that happen to HTML elements.An HTML event can be something the browser does, or something a user does.Here are some examples of HTML events:- An HTML web page has finished loading- An HTML input field was changed- An HTML button was clicked```" }, { "title": "Debugging JavaScript", "url": "/posts/debugging-in-javascript/", "categories": "Blogging, programming", "tags": "development programming debugging javascript", "date": "2022-03-06 20:40:00 +0530", "snippet": "IntroductionWe debug our code irrespective of the language it is written in, so that we can find and fix errors. Fixing bugs is a very good learning path to dive deep into something and figure out why it occurs and how things operate under the hood.Debugging in JavaScriptTest Code with error:Expected output is 37.5(function (app) { &#39;use strict&#39;; app.divide = function (x, y) { return x / y; }; app.complicatedFormula = function (x) { let result = x * 3 + 2; x += 4; result += this.divide(result, 2); return result; }})(window.app = window.app || {});console.log(app.complicatedFormula(23));1) Basic Debugging - (Using console log, error, and warning)console.error(&#39;This is an error&#39;);console.warn(&#39;This is an warning&#39;);We can use log statements and log the values at different steps and thereby find the issue. Using console log in the above test code is demonstrated below.(function (app) { &#39;use strict&#39;; app.divide = function (x, y) { console.log(x/y); return x / y; }; app.complicatedFormula = function (x) { let result = x * 3 + 2; result += 4; console.log(result); result = this.divide(result, 2); console.log(result); return result; }})(window.app = window.app || {});console.log(app.complicatedFormula(23));2) Using chrome devtoolsWe can use the source tab in google chrome dev tools to add breakpoints to the JavaScript file. If we add breakpoint at a certain line, the debugger will pause the website and allow us to inspect the code. We can go line by line and inspect the values of each variables and thereby find the issue/error.3) Debugging in VSCodeTo attach the debugger to VSCode: Goto the Run and Debug tab in VSCode Click on Create a launch.json file In environment select your browser (chrome in our case)This will create a new folder .vscode in the root folder with a file named launch.json. The file will be in the following format{ &quot;version&quot;: &quot;0.2.0&quot;, &quot;configurations&quot;: [ { &quot;type&quot;: &quot;pwa-chrome&quot;, &quot;request&quot;: &quot;launch&quot;, &quot;name&quot;: &quot;Debug on Chrome&quot;, &quot;url&quot;: &quot;http://localhost:8080&quot;, &quot;webRoot&quot;: &quot;${workspaceFolder}&quot; } ]} Click on the run and debug option, this will pause the website and take you to point where we have added a breakpoint in vscode.We can also use the debug console in vscode to observe the values similar to how it’s seen in the chrome console tab." }, { "title": "JavaScript Basic Concepts", "url": "/posts/basics-of-javascript/", "categories": "Blogging, programming", "tags": "development programming javascript", "date": "2022-03-03 22:10:00 +0530", "snippet": "IntroductionWe structure the web using HTML and style it using CSS. We use JavaScript to power the web with scripting. JavaScript is a powerful scripting language that allows us to create dynamic pages and interactive applications on the web.History Of JavaScriptIn the mid 90’s when Netscape navigator was new, they commissioned a new scripting language. Brendan Eich designed this scripting language. Brendan created and shipped a version of the scripting language (called LiveScript) within 2 weeks along with the Navigator beta release in 1995. The name was later changed from LiveScript to JavaScript. Microsoft create something similar to Javascript called JScript for internet explorer. With the rise in popularity of Internet Explorer, Microsoft could dictate the terms and could thus push out JavaScript for a while in favour of JScript. In 2004, the successor of Netscape, Mozilla Firefox browser was released and JavaScript started to take back the market share. In 2008, Google released Google Chrome and brought back more life to JavaScript. (Google Chrome introduced the V8 JavaScript engine that was faster than it’s counterparts). AJAX also came around during this time with the idea that we don’t have to reload a page to send data back to the server or get it from the server. This led to creation of many libraries like JQuery, MooTools etc. As Javascript started to become more popular, it’s standardisation started to solidify for it. In 2009, ECMAScript 5 came out, it was the start of modern javaScript. In 2015, ECMAScript 6 was released which is the current version of JavaScript. It can be compared to HTML5 and CSS3.Basics of JavaScriptWe can write JavaScript inline in the html document inside a script tag in the body. Since an HTML document renders from top to bottom, we place the script tag at the bottom of the body since, scripts can sometimes be large and take a lot of time to load.Logging to the console Inline &amp;lt;script&amp;gt; console.log(&#39;Hello World!&#39;);&amp;lt;/script&amp;gt; From another file // create a script tag and reference the app.js file inside it as src// Inside the app.js fileconsole.log(&#39;Hello World from another file!&#39;); VariablesVariables hold data. They are used to pass around data to other locations and use it. We have 3 different ways to declare variables var - It has been there since the beginning. The type doesn’t matter and can be changed throughout. Not a preferred way of declaring a variable. let - Scoped variable. The type can be changed. If something is designed to change, use let. Can be declared first and value can be assigned later. const - This value will be constant. Unless you know something is designed to changes, use const. Needs to be defined during declaration var var testString = &#39;this is a test&#39;; var testNumber = 98; console.log(testString); console.log(testNumber); let let testString = &#39;this is a test&#39;; testString = &#39;This is a better string&#39;; const const testString = &#39;this is a test&#39;; testString = &#39;This is a better string&#39;; // causes error here If we declare a variable, but haven’t assigned a value to it, it’s value will be undefined. Type of the variable is inferred from the value assigned to it. var i;console.log(i); // undefined Hoisting - It is the default behavior of moving all the declarations at the top of the scope before code execution. Hoisting can only be done for var. let doesn’t support Hoisting. i = 5;console.log(i);var i = 2; During code execution this will be changed to : var i;i = 5;console.log(i);i = 2; String interpolation const firstName = &#39;First&#39;;const lastName = &#39;Last&#39;;console.log(`Hello ${firstName} ${lastName}`); // string interpolation - we use backtick (`) for string interpolation ArraysAn array is a special variable, which can hold more than one value.It uses a zero based counting system. First element will be at index 0.const people = [&#39;Tim&#39;, &#39;Sue&#39;, &#39;Mary&#39;, &#39;John&#39;];people.push(&#39;Grey&#39;); // add element to the arraypeople.pop(); // pops the last element from the array.people.indexOf(&#39;Tim&#39;); // gives 0Important methods: array.filter() const people = [&#39;Tim&#39;, &#39;Sue&#39;, &#39;Mary&#39;, &#39;John&#39;];const coolPeople = people.filter(function (person) { return person.startsWith(&#39;T&#39;) === true;});console.log(coolPeople); array.map() const people = [&#39;Tim&#39;, &#39;Sue&#39;, &#39;Mary&#39;, &#39;John&#39;];const firstLetters = people.map(function (person) { return person.substring(0, 1);});console.log(firstLetters); In JavaScript, arrays use numbered indexes. In JavaScript, objects use named indexes.Conditionals if, else if, else :const firstName = &#39;Bob&#39;;const lastName = &#39;Mc&#39;;if (firstName === &#39;Bob&#39; &amp;amp;&amp;amp; lastName === &#39;Mc&#39;) { console.log(&#39;Hello teacher&#39;); // prints this} else { console.log(&#39;Hello student&#39;);} Difference between ‘==’ and ‘===’const x = &#39;1&#39;;const y = 1;if (x == y) { console.log(&#39;Two values are equal&#39;); // prints this though the values are not equal.}if (x === y) { console.log(&#39;Two values are equal&#39;); // will not print this} switch :const day = &#39;Tuesday&#39;;switch (day) { case &#39;Monday&#39;: console.log(&#39;Welcome to the first day of the week&#39;); break; case &#39;Tuesday&#39;: console.log(&#39;I hope your week is going well&#39;); break; default: console.log(&#39;I don\\&#39;t know which day of the week that is&#39;); break;}Loops forconst people = [&#39;Tim&#39;, &#39;Sue&#39;, &#39;Dan&#39;, &#39;Mary&#39;, &#39;Bob&#39;];for (let i = 0; i &amp;lt; people.length; i++) { console.log(people[i]);} for ofconst people = [&#39;Tim&#39;, &#39;Sue&#39;, &#39;Dan&#39;, &#39;Mary&#39;, &#39;Bob&#39;];for (const person of people) { console.log(person);} foreachconst people = [&#39;Tim&#39;, &#39;Sue&#39;, &#39;Dan&#39;, &#39;Mary&#39;, &#39;Bob&#39;];people.forEach(function(person){ console.log(person);}); whileconst people = [&#39;Tim&#39;, &#39;Sue&#39;, &#39;Dan&#39;, &#39;Mary&#39;, &#39;Bob&#39;];while (people.length &amp;gt; 0) { console.log(people.pop());} for inconst person = { firstName: &#39;Tim&#39;, lastName: &#39;Corey&#39;, age: 31, isAlive: true, address: { city: &#39;Dallas&#39;, state: &#39;Texas&#39; }, fullName: function () { return `${this.firstName} ${this.lastName}`; }};for (const prop in person) { // console.log(`${prop}: ${person[prop]}`); if (person.hasOwnProperty(prop)) { console.log(`${prop}: ${person[prop]}`); }}FunctionsA JavaScript function is a block of code designed to perform a particular task.function add(x, y) { return x + y;}console.log(add(1,2)); using default values in function parametersfunction add(x = 2, y = 6) { return x + y;}console.log(add());Arrow FunctionsSubtraction using arrow functionconst subtract = (x, y) =&amp;gt; { return x - y;}// orconst subtract = (x, y) =&amp;gt; x - y;Filtering using arrow functionconst people = [&#39;Tim&#39;, &#39;Sue&#39;, &#39;Dan&#39;, &#39;Mary&#39;, &#39;Bob&#39;];const filtered = people.filter(p =&amp;gt; p.substring(0, 1) === &#39;T&#39;);ObjectsIn JavaScript, almost “everything” is an object.All JavaScript values, except primitives, are objects. A primitive value is a value that has no properties or methods. A primitive data type is data that has a primitive value. Primitive values are immutable (they are hardcoded and therefore cannot be changed). if x = 3.14, you can change the value of x. But you cannot change the value of 3.14.Object values are written as name : value pairs (name and value separated by a colon).const person = { //key:value pairs firstName: &#39;Bob&#39;, //propertyName:value lastName: &#39;Builder&#39;};A more complex object with sub objectsconst person = { //key:value pairs firstName: &#39;Bob&#39;, lastName: &#39;Builder&#39;, age: 31, isAlive: true, address: { city: &#39;Dallas&#39;, state: &#39;Texas&#39; }, fullName: function () { return `${this.firstName} ${this.lastName}`; }};person.firstName = &#39;Bobby&#39;;person.address.country = &#39;USA&#39;;console.log(person.fullName());A JavaScript object is a collection of named valuesDeconstructing objectsconst person = { //key:value pairs firstName: &#39;Tim&#39;, lastName: &#39;Corey&#39;, age: 31, isAlive: true, address: { city: &#39;Dallas&#39;, state: &#39;Texas&#39; }, fullName: function () { return `${this.firstName} ${this.lastName}`; }};// Deconstructing the objectconst {firstName, age, address: {city}} = person;console.log(firstName);// This is similar to doing:const fn = person.firstName;const age = person.age;const city = person.address.city;this keywordThe this keyword refers to different objects depending on how it is used: In an object method, this refers to the object. Alone, this refers to the global object (Window in DOM). In a function, this refers to the global object. In a function, in strict mode, this is undefined. In an event, this refers to the element that received the event. Methods like call(), apply(), and bind() can refer this to any object.JSON (JavaScript Object Notation)JSON is a format for storing and transporting data. API’s transfer data in the form of JSON.The JSON syntax is derived from JavaScript object notation syntax, but the JSON format is text only The JSON format is syntactically identical to the code for creating JavaScript objects.JSON names require double quotes. JavaScript names do not.Because of this similarity, a JavaScript program can easily convert JSON data into native JavaScript objects.const person = { firstName: &#39;Tim&#39;, lastName: &#39;Corey&#39;, age: 31, isAlive: true, address: { city: &#39;Dallas&#39;, state: &#39;Texas&#39; }, fullName: function () { return `${this.firstName} ${this.lastName}`; }};const recievedInfo = JSON.stringify(person);const parsedInfo = JSON.parse(recievedInfo);console.log(parsedInfo.firstName); Converts javascript object to JSON:JSON.stringify(object) Converts JSON back to javascript object:JSON.parse(json)ClassesClasses are blueprints. The instance of a class creates a new object off the blueprint.ECMAScript 2015, also known as ES6, introduced JavaScript Classes. JavaScript Classes are templates for JavaScript Objects.// class = blueprint, class instance = houseclass Person { constructor(firstName, lastName) { this.firstName = firstName; this.lastName = lastName; }}const person1 = new Person(&#39;Tim&#39;, &#39;Corey&#39;);const person2 = new Person(&#39;Sue&#39;, &#39;Storm&#39;);console.log(person1.firstName);console.log(person2.firstName);private fields, get, setget, set helps protect our data.class Person { #social = &#39;&#39;; // private variable, can only be accessed inside the class using get/set constructor(firstName, lastName) { this.firstName = firstName; this.lastName = lastName; } get ssn() { return `***-**-${this.#social.substr(this.#social.length - 4)}`; } set ssn(social) { this.#social = social; } getFullName = () =&amp;gt; `${this.firstName} ${this.lastName}`;}const person1 = new Person(&#39;Tim&#39;, &#39;Corey&#39;);person1.ssn = &#39;123-45-5789&#39;; // accessing set(){}console.log(person1.ssn);console.log(person1.getFullName());Note: JavaScript DocumentationIIFE (Immediately Invoking Function Expression)It is a JavaScript function that runs as soon as it is defined.syntax:(function () { /* ... */})();In the syntax the first set of parenthesis () will contain the function and the next set (); will execute the function immediately, which will pass in parameter names.Example: suppose we are using an external library in our project and it has a method with the same name as one of our local methods, this will cause confusion when calling the method by it’s name.function greetUser() { console.log(&#39;Hello User&#39;);}function greetUser() { console.log(&#39;Welcome to the app&#39;);}greetUser(); // This will log: &quot;Welcome to the app&quot; the second function overrides the first one.We can solve this by creating an IIFE:// IIFE// Everything inside this module is inside &#39;app&#39; namespace(function (app) { app.greetUser = function () { console.log(&#39;Hello user&#39;); }})(window.app = window.app || {});function greetUser() { console.log(&#39;Welcome to the app&#39;);}greetUser();app.greetUser(); // function is inside the namespace appWe can also extend an IIFE as follows:(function (app) { app.greetUser = function () { console.log(&#39;Hello user&#39;); } app.Person = class { constructor(firstName, lastName) { this.firstName = firstName; this.lastName = lastName; } }})(window.app = window.app || {});function greetUser() { console.log(&#39;Welcome to the app&#39;);}greetUser();app.greetUser();// Extending the IIFE(function (app) { app.goodByeUser = function () { console.log(&#39;GoodBye&#39;); }})(window.app = window.app || {});app.goodByeUser();ScopeIt is the concept of where we can see the variables.Scope determines the accessibility (visibility) of variables.JavaScript has 3 types of scope: Block scope Function scope Global scopevar a = 4;// functions create a new scopefunction testing() { var a = 5; console.log(`Inside testing(): ${a}`);}testing(); // prints 4console.log(`global: ${a}`); // prints 5Now if we do this inside an if blockvar b = 4;if (true) { var b = 5;}console.log(b); // prints 5, because the whole thing is a single scope for var If we use let/const, they are not scoped at the function level, but at the block level.let b = 4;if (true) { let b = 5; console.log(b); // prints 5} // let only lives till end of this block / bracesconsole.log(b); // prints 4use StrictIt checks for certain things a shows an error for cases where javascript normally doesn’t have an issue.“use strict”; Defines that JavaScript code should be executed in “strict mode”.Strict mode is declared by adding “use strict&quot;; to the beginning of a script or a function. Declared at the beginning of a script, it has global scope (all code in the script will execute in strict mode): Declare variables before you use them. Checks for duplicate parameters in a function. Deleting a variable (or object), functions is not allowed. Writing to a read-only property is not allowed. &#39;use strict&#39;;a = 2;console.log(a); // shows error since variable not declared. Best Practices Add ‘use strict’; to the top of every file and IIFE. Do not use var - Use let or const instead. Prefer const. Naming - use camelCase for variables, functions, etc. and PascalCase for classes. Use IIFE’s whenever makes sense - it almost always makes sense. Just because you can, doesn’t mean you should. Use a seperate file for your JavaScript. Use semi-colons. Don’t Assume." }, { "title": "C# Basic Concepts", "url": "/posts/concepts-csharp/", "categories": "Blogging, programming", "tags": "development programming csharp", "date": "2022-02-26 00:10:00 +0530", "snippet": "IntroductionC# is a statically-typed programming language, meaning everything will have a type at compile-time. When we assing a value to a name, it is called as defining a variable.We can define a variable either by explicitly specifying it’s type or by letting the complier infer it’s type based on the assigned value(type inference).int expVar = 7; // Explicitly typedvar impVar = 7; // Implicitly typedObject Oriented Concepts C# is an object-oriented language and requires all the functions to be defined in a class. The class keyword is used to define a class. Objects (or instances) are created by using the new keyword. class Calculator{ // ...}var calculator = new Calculator(); A function within a class is referred to as a method. Each method can have zero or more parameters. All parameters must be explicitly typed, there is no type inference for parameters The return type must also be made explicit. Values are returned from methods using the return keyword. To allow a method to be called by code in other files, the public access modifier must be added. class Calculator{ public int Add(int x, int y) { return x + y; }} Methods are invoked using dot (.) syntax on an instancevar calculator = new Calculator();var sum_v1 = calculator.Add(1, 2);var sum_v2 = calculator.Add(x: 1, y: 2); Scope in C# is defined between the { and } characters. C# supports single line comments // and multi-line comments inserted betewwn /* and */" }, { "title": "Basics of C# Programming Language", "url": "/posts/basics-of-csharp/", "categories": "Blogging, programming", "tags": "development programming csharp", "date": "2022-02-25 11:35:00 +0530", "snippet": "IntroductionC# is an object-oriented programming language developed by Microsoft. It enables developers to build applications that run in .NET.This brings the question, what is .NET?.NET is the managed environment within which C# runs, so you get access to the entire .NET ecosystem, including all packages on nuget.org.Code snippet for Hello World program using C#using System;class Hello{ static void Main() { Console.WriteLine(&quot;Hello, World&quot;); }}Some of the features of the language Statically-typed: Identifiers have type set at compile time (not during run time). This gurantees type safety. Object-oriented: It is a class based language with features such as inheritance, polymorphism, interfaces, and encapsulation. Declarative: Programming what is to be done, as opposed to how it is done. Functional: Functions are first-class data types that can be passed as arguments to and returned from other functions. Generic: Algorithms are written in terms of types to be specified later when they are instantiated. Here the type will be provided as parameters. Lazy (Deferred execution): The compiler will put off evaluating an item until required. Integrated Querying: C# has a feature called LINQ (Language Integrated Query), this enable lazy query loading within the language, not only its own objects but, also, external data sources through formats such as XML, JSON, SQL, NoSQL DBs and event streams. Type inference: The compiler will often figure out the type of an identifier by itself.Platform SupportInitially .NET used to be Windows-only. But with the release of .NET Core as well as Mono, C# can be used in Mac, Linux, and on mobile platforms too." }, { "title": "Deploying a static website to Docker", "url": "/posts/deploy-in-docker/", "categories": "Blogging, deployment", "tags": "web development deployment docker", "date": "2022-02-18 15:10:00 +0530", "snippet": "IntroductionMost of us are familiar with virtual machines, you have an entire operating system and all the necessary programs (basically a full computer), but it’s virtual.Docker is even smaller, it doesn’t replicate the entire computer, just parts of it and our required OS as layers. We can install our site into a docker container. The advantage of using docker is that we can pass around this container with the OS, the website installed, and everything already configured for the website to run properly.This enables us to scale up a website quickly. Instead of deploying it to multiple locations, we can create multiple identical copies of our docker container and load balance between the different containers. It’s also easy to deploy it to cloud services.Getting StartedTo get started, install docker desktop on your computer. Now go to DockerHub and search for httpd From the tag section filter for alpine. httpd:alpine provides a complete linux OS with a web server. We will use this container to package up our website so that we can deploy an image of our site. Provided you are using VSCode as your text editor, you can install the docker extension for ease of working with dockerfiles. Create a new file in your root directory called dockerfile (no extensions). The contents of the file will be the following: FROM httpd:alpine COPY ./ /usr/local/apache2/htdocs/ So, what does this do? First provide the location we are building from. In our case httpd:alpine, then copy the html, css, and other necessary files from our filepath to the path specified for httpd which is /usr/local/apache2/htdocs/ Next, we need to create a docker image for our website To build our image from the dockerfile run the following command in the terminal docker build -t &amp;lt;name-of-the-docker-image&amp;gt; . After building, to check if the image is created, run docker images An image is like a read-only image of our application, if we need to run an image, we need a container docker run --name &amp;lt;container-name&amp;gt; -p 8080:80 &amp;lt;name-of-image-to-run-off-of&amp;gt; // 8080 - Container runs in this port locally // 80 - http port in the apache server Now goto localhost:8080 and we will have our website up and running.Basic CommandsImage- docker build -t name:tag . // build a new image- docker images // show all images- docker image history imageid // to see the history of image - docker rmi imageid // to remove imageContainer- docker ps -a // show all containers- docker stop conatinerid // to stop a running container- docker start containerid // to start a container- docker rm containerid // removes the container" }, { "title": "Deploying a static website to IIS", "url": "/posts/deploy-in-iis/", "categories": "Blogging, deployment", "tags": "web development deployment iis", "date": "2022-02-18 00:21:00 +0530", "snippet": "IntroductionLet’s discuss on how we can deploy a static website to Microsoft’s web server IIS (Internet Information Services). Here we will be going through the steps to successfully deploy our website onto IIS.Initial SetupProvided you are using a windows machine, first you’ll need to check if IIS is installed on the machine. Hit your windows key and search for windows features, this will pop up a list of windows features. Scroll down to find Internet Information Service and if the checkbox is checked, it means it’s already installed and we are ready to go. Otherwise you can click on the checkbox and give OK.Overview of IISNow that the installation is out of the way, let’s open up IIS. Clicking on the Basic settings we can get the physical path for our website on our local machine. On clicking the Explore option, we can open up the path of our website which will be something like this inetpub/wwwroot. It will contain 2 files iisstart.html and iisstart.png, this is for displaying a default page of IIS.If you want, you can get rid of them.DeploymentCopy and paste our index.html file and the other html/css files to this folder inetpub/wwwroot. Browsing to localhost on the browser will display the contents of the index.html file. And that’s how we deploy a static website to IIS." } ]
